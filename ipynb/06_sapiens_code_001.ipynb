{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff607a2",
   "metadata": {},
   "source": [
    "# ì¤‘ê°„ ì‚°ì¶œë¬¼ ì¡´ì¬í•˜ëŠ” ë°©ì‹\n",
    "Frame, json, vis, output_mp4 ì´ 4ê°œì˜ ì‚°ì¶œë¬¼ì„ ë§Œë“¤ë©° ëŒì•„ê°€ëŠ” ì½”ë“œ\n",
    "\n",
    "í•´ë‹¹ ì½”ë“œì—ì„œ Frame, vis ê°™ì€ Frame ë‹¹ outputì„ ë§Œë“œëŠ”ë° ì‹œê°„ì´ ê½¤ë‚˜ ì˜¤ë˜ê±¸ë¦¼.\n",
    "\n",
    "ì¶”í›„, ìˆ˜ì • ì˜ˆì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6c95dd-9035-41b6-b751-0b86d3d2b486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU count: 1\n",
      "mmpose: 1.3.2 | mmdet: 3.2.0 | mmengine: 0.10.7 | mmcv: 2.1.0\n",
      "\n",
      "[PATH CHECK]\n",
      "FRAME_DIR    | DIR  | OK | ../data/Patient_data/new_code/frames/M01_VISIT2_ìƒì§€_frame\n",
      "JSON_DIR     | DIR  | OK | ../data/Patient_data/new_code/json/M01_VISIT2_ìƒì§€_json\n",
      "VIS_DIR      | DIR  | OK | ../data/Patient_data/new_code/vis/M01_VISIT2_ìƒì§€_vis\n",
      "MP4_PATH     | FILE | OK | ../../../../data/ê¹€ì› ë³´ì‚°ì§„ ì—°êµ¬/M01_VISIT2_ìƒì§€.MP4\n",
      "OUTPUT_MP4   | FILE | OK | ../data/Patient_data/new_code/output/M01_VISIT2_ìƒì§€_output.mp4\n",
      "DET_CONFIG   | FILE | OK | ../sapiens/pose/demo/mmdetection_cfg/rtmdet_m_640-8xb32_coco-person_no_nms.py\n",
      "DET_CKPT     | FILE | OK | ../sapiens/pose/checkpoints/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n",
      "POSE_CONFIG  | FILE | OK | ../sapiens/pose/configs/sapiens_pose/coco/sapiens_0.3b-210e_coco-1024x768.py\n",
      "POSE_CKPT    | FILE | OK | ../sapiens/pose/checkpoints/sapiens_0.3b/sapiens_0.3b_coco_best_coco_AP_796.pth\n"
     ]
    }
   ],
   "source": [
    "import os, sys, torch\n",
    "import mmpose, mmdet, mmengine, mmcv\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU count:\", torch.cuda.device_count())\n",
    "print(\"mmpose:\", mmpose.__version__, \"| mmdet:\", mmdet.__version__, \"| mmengine:\", mmengine.__version__, \"| mmcv:\", mmcv.__version__)\n",
    "\n",
    "mp4_name = \"M01_VISIT2_ìƒì§€\"  # íŒŒì¼ëª…ë§Œ\n",
    "\n",
    "paths_tpl = {\n",
    "    \"MP4_PATH\":    \"../../../../data/ê¹€ì› ë³´ì‚°ì§„ ì—°êµ¬/{mp4_name}.MP4\",\n",
    "    \"FRAME_DIR\":   \"../data/Patient_data/new_code/frames/{mp4_name}_frame\",\n",
    "    \"JSON_DIR\":    \"../data/Patient_data/new_code/json/{mp4_name}_json\",\n",
    "    \"VIS_DIR\":     \"../data/Patient_data/new_code/vis/{mp4_name}_vis\",\n",
    "    \"OUTPUT_MP4\":  \"../data/Patient_data/new_code/output/{mp4_name}_output.mp4\",\n",
    "    \"DET_CONFIG\":  \"../sapiens/pose/demo/mmdetection_cfg/rtmdet_m_640-8xb32_coco-person_no_nms.py\",\n",
    "    \"DET_CKPT\":    \"../sapiens/pose/checkpoints/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\",\n",
    "    \"POSE_CONFIG\": \"../sapiens/pose/configs/sapiens_pose/coco/sapiens_0.3b-210e_coco-1024x768.py\",\n",
    "    \"POSE_CKPT\":   \"../sapiens/pose/checkpoints/sapiens_0.3b/sapiens_0.3b_coco_best_coco_AP_796.pth\",\n",
    "}\n",
    "\n",
    "# 1) {mp4_name} ì¹˜í™˜\n",
    "paths = {k: v.format(mp4_name=mp4_name) for k, v in paths_tpl.items()}\n",
    "\n",
    "# 2) ë””ë ‰í„°ë¦¬ ìƒì„± (ì¹˜í™˜ í›„ì—!)\n",
    "for k in (\"FRAME_DIR\", \"JSON_DIR\", \"VIS_DIR\"):\n",
    "    Path(paths[k]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# (ì„ íƒ) OUTPUT_MP4ëŠ” íŒŒì¼ì´ë¯€ë¡œ ë¶€ëª¨ í´ë”ë§Œ ë³´ì¥\n",
    "Path(Path(paths[\"OUTPUT_MP4\"]).parent).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 3) ê²½ë¡œ ì²´í¬\n",
    "print(\"\\n[PATH CHECK]\")\n",
    "for k in (\"FRAME_DIR\", \"JSON_DIR\", \"VIS_DIR\",\n",
    "          \"MP4_PATH\", \"OUTPUT_MP4\", \"DET_CONFIG\", \"DET_CKPT\", \"POSE_CONFIG\", \"POSE_CKPT\"):\n",
    "    p = paths[k]\n",
    "    exists = Path(p).exists()\n",
    "    typ = \"DIR \" if k in (\"FRAME_DIR\", \"JSON_DIR\", \"VIS_DIR\") else \"FILE\"\n",
    "    print(f\"{k:12s} | {typ} | {'OK' if exists else 'MISSING'} | {p}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4923e23-090c-490b-ba89-2a7293fc2cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] CWD: /workspace/nas203/ds_RehabilitationMedicineData/IDs/Kimjihoo/3_project_HCCmove/ipynb\n",
      "[INFO] Video : /workspace/nas203/ds_RehabilitationMedicineData/data/ê¹€ì› ë³´ì‚°ì§„ ì—°êµ¬/M01_VISIT2_ìƒì§€.MP4\n",
      "[INFO] Output: /workspace/nas203/ds_RehabilitationMedicineData/IDs/Kimjihoo/3_project_HCCmove/data/Patient_data/new_code/frames/M01_VISIT2_ìƒì§€_frame\n",
      "FPS: 29.970 | ì´ í”„ë ˆì„: 11370 | ì €ì¥ ì˜ˆì •: 11370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting frames:   0% 30/11370 [00:05<37:50,  4.99frame/s] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     63\u001b[0m out_path \u001b[38;5;241m=\u001b[39m frame_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m06d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 64\u001b[0m ok \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMWRITE_JPEG_QUALITY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m95\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ok:\n\u001b[1;32m     66\u001b[0m     saved \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- MP4_PATH â†’ FRAME_DIR: í”„ë ˆì„ ì¶”ì¶œ ì €ì¥ ---\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ê¸°ì¡´ ì…€ì—ì„œ ë§Œë“  paths ì‚¬ìš©\n",
    "mp4_path   = Path(paths[\"MP4_PATH\"])\n",
    "frame_dir  = Path(paths[\"FRAME_DIR\"])\n",
    "\n",
    "# (ì˜µì…˜) ì• Nì´ˆë§Œ ì €ì¥í•˜ê³  ì‹¶ìœ¼ë©´ ìˆ«ìë¥¼ ë„£ê³ , ì „ì²´ ì €ì¥ì€ None\n",
    "DURATION_SEC = None  # ì˜ˆ: 20\n",
    "\n",
    "# ëŒ€ì†Œë¬¸ì í™•ì¥ì ì´ìŠˆ ëŒ€ë¹„(ëŒ€ì•ˆ ê²½ë¡œ ìë™ íƒìƒ‰)\n",
    "if not mp4_path.exists():\n",
    "    alt = mp4_path.with_suffix(\".mp4\") if mp4_path.suffix != \".mp4\" else mp4_path.with_suffix(\".MP4\")\n",
    "    if alt.exists():\n",
    "        print(f\"[INFO] ì…ë ¥ ë¹„ë””ì˜¤ ëŒ€ì•ˆ ê²½ë¡œ ì‚¬ìš©: {alt}\")\n",
    "        mp4_path = alt\n",
    "\n",
    "print(\"[INFO] CWD:\", os.getcwd())\n",
    "print(\"[INFO] Video :\", mp4_path.resolve())\n",
    "print(\"[INFO] Output:\", frame_dir.resolve())\n",
    "\n",
    "cap = cv2.VideoCapture(str(mp4_path))\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {mp4_path}\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) or 0.0\n",
    "total_prop = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "total_frames = int(total_prop) if total_prop and total_prop > 0 else -1\n",
    "\n",
    "# ì €ì¥í•  ëª©í‘œ í”„ë ˆì„ ìˆ˜ ê³„ì‚°(ì „ì²´ ë˜ëŠ” ì• Nì´ˆ)\n",
    "if DURATION_SEC is not None and fps > 0:\n",
    "    target_frames = int(round(DURATION_SEC * fps))\n",
    "    if total_frames > 0:\n",
    "        target_frames = min(target_frames, total_frames)\n",
    "else:\n",
    "    target_frames = total_frames if total_frames > 0 else None\n",
    "\n",
    "print(f\"FPS: {fps:.3f} | ì´ í”„ë ˆì„: {total_frames} | ì €ì¥ ì˜ˆì •: {target_frames if target_frames is not None else 'ì „ì²´(ì‹œê°„ ê¸°ì¤€)'}\")\n",
    "\n",
    "saved = 0\n",
    "idx = 0\n",
    "pbar_total = target_frames if target_frames is not None else (int(fps * (DURATION_SEC or 10)) or 100)\n",
    "pbar = tqdm(total=pbar_total, desc=\"Extracting frames\", unit=\"frame\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # ì‹œê°„ ì œí•œ ëª¨ë“œì¼ ë•Œ( FPSë¥¼ ëª» ì½ëŠ” ê²½ìš° í¬í•¨ )\n",
    "    pos_msec = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "\n",
    "    if target_frames is not None:\n",
    "        if idx >= target_frames:\n",
    "            break\n",
    "    elif DURATION_SEC is not None:\n",
    "        if pos_msec >= DURATION_SEC * 1000:\n",
    "            break\n",
    "\n",
    "    out_path = frame_dir / f\"frame_{idx:06d}.jpg\"\n",
    "    ok = cv2.imwrite(str(out_path), frame, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "    if ok:\n",
    "        saved += 1\n",
    "        if target_frames is not None:\n",
    "            pbar.update(1)\n",
    "        else:\n",
    "            # ì‹œê°„ ê¸°ì¤€ì¼ ë•Œ ëŒ€ëµ ì§„í–‰ë¥ \n",
    "            pbar.update(1 if pbar.n < pbar.total else 0)\n",
    "    idx += 1\n",
    "\n",
    "pbar.close()\n",
    "cap.release()\n",
    "print(f\"ì™„ë£Œ: {saved}ì¥ ì €ì¥ â†’ {frame_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae96644-a8b4-4b53-afd5-2eefc39c434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmengine/utils/package_utils.py:48: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n",
      "/opt/conda/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  _bootstrap._exec(spec, module)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../sapiens/pose/checkpoints/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n",
      "Loads checkpoint by local backend from path: ../sapiens/pose/checkpoints/sapiens_0.3b/sapiens_0.3b_coco_best_coco_AP_796.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "missing keys in source state_dict: head.deconv_layers.1.weight, head.deconv_layers.1.bias, head.deconv_layers.1.running_mean, head.deconv_layers.1.running_var, head.deconv_layers.4.weight, head.deconv_layers.4.bias, head.deconv_layers.4.running_mean, head.deconv_layers.4.running_var, head.conv_layers.1.weight, head.conv_layers.1.bias, head.conv_layers.1.running_mean, head.conv_layers.1.running_var, head.conv_layers.4.weight, head.conv_layers.4.bias, head.conv_layers.4.running_mean, head.conv_layers.4.running_var\n",
      "\n",
      "ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ âœ…\n"
     ]
    }
   ],
   "source": [
    "# ì• ì…€ì—ì„œ pathsë¥¼ ë§Œë“  ìƒíƒœì—¬ì•¼ í•¨\n",
    "assert 'paths' in globals(), \"ì• ì…€ì—ì„œ pathsë¥¼ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.\"\n",
    "\n",
    "import mmpretrain  # VisionTransformer ë“±ë¡\n",
    "\n",
    "import mmcv\n",
    "from pathlib import Path\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmpose.apis import init_model as init_pose_estimator, inference_topdown\n",
    "from mmpose.utils import adapt_mmdet_pipeline\n",
    "from mmpose.registry import VISUALIZERS\n",
    "from mmpose.evaluation.functional import nms\n",
    "from mmpose.structures import merge_data_samples, split_instances\n",
    "\n",
    "# paths ë”•ì…”ë„ˆë¦¬ì—ì„œ ê²½ë¡œ ë°”ì¸ë”©\n",
    "DET_CONFIG  = paths[\"DET_CONFIG\"]\n",
    "DET_CKPT    = paths[\"DET_CKPT\"]\n",
    "POSE_CONFIG = paths[\"POSE_CONFIG\"]\n",
    "POSE_CKPT   = paths[\"POSE_CKPT\"]\n",
    "\n",
    "# (ì„ íƒ) í”„ë ˆì„ í´ë”ë„ ê°™ì´ ì¨ì•¼ í•œë‹¤ë©´\n",
    "DATA_DIR = paths[\"FRAME_DIR\"]\n",
    "\n",
    "# (ê¶Œì¥) ì¡´ì¬ ì—¬ë¶€ ì²´í¬\n",
    "for k in (\"DET_CONFIG\", \"DET_CKPT\", \"POSE_CONFIG\", \"POSE_CKPT\"):\n",
    "    p = Path(globals()[k])\n",
    "    assert p.exists(), f\"{k} ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {p}\"\n",
    "\n",
    "# detector\n",
    "detector = init_detector(DET_CONFIG, DET_CKPT, device=\"cuda:0\")\n",
    "detector.cfg = adapt_mmdet_pipeline(detector.cfg)\n",
    "\n",
    "# pose estimator (override_ckpt_meta ì œê±°)\n",
    "pose_estimator = init_pose_estimator(\n",
    "    POSE_CONFIG, POSE_CKPT,\n",
    "    device=\"cuda:0\",\n",
    "    cfg_options=dict(model=dict(test_cfg=dict(output_heatmaps=False)))\n",
    ")\n",
    "\n",
    "# ì‹œê°í™”ê¸°\n",
    "visualizer = VISUALIZERS.build(pose_estimator.cfg.visualizer)\n",
    "visualizer.set_dataset_meta(pose_estimator.dataset_meta, skeleton_style=\"mmpose\")\n",
    "\n",
    "print(\"ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ âœ…\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d81768-ed2c-4c75-9765-21263cadf5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ 31ì¥ â†’ 15fpsìš© 16ì¥ ì„ íƒ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0% 0/16 [00:00<?, ?it/s]\u001b[A/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1695392020201/work/aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "\n",
      "  6% 1/16 [00:01<00:21,  1.43s/it]\u001b[A\n",
      " 12% 2/16 [00:02<00:13,  1.07it/s]\u001b[A\n",
      " 19% 3/16 [00:02<00:10,  1.27it/s]\u001b[A\n",
      " 25% 4/16 [00:03<00:08,  1.36it/s]\u001b[A\n",
      " 31% 5/16 [00:03<00:07,  1.48it/s]\u001b[A\n",
      " 38% 6/16 [00:04<00:06,  1.53it/s]\u001b[A\n",
      " 44% 7/16 [00:05<00:05,  1.58it/s]\u001b[A\n",
      " 50% 8/16 [00:05<00:04,  1.62it/s]\u001b[A\n",
      " 56% 9/16 [00:06<00:04,  1.63it/s]\u001b[A\n",
      " 62% 10/16 [00:06<00:03,  1.66it/s]\u001b[A\n",
      " 69% 11/16 [00:07<00:03,  1.66it/s]\u001b[A\n",
      " 75% 12/16 [00:08<00:02,  1.65it/s]\u001b[A\n",
      " 81% 13/16 [00:08<00:01,  1.61it/s]\u001b[A\n",
      " 88% 14/16 [00:09<00:01,  1.61it/s]\u001b[A\n",
      " 94% 15/16 [00:09<00:00,  1.64it/s]\u001b[A\n",
      "100% 16/16 [00:10<00:00,  1.52it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì™„ë£Œ. ì„±ê³µ 16, ì‹¤íŒ¨ 0, ì¶œë ¥: ../data/Patient_data/new_code/json/M01_VISIT2_ìƒì§€_json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 30â†’15fps ë‹¤ìš´ìƒ˜í”Œ + ì£¼ê¸°ì  ê²€ì¶œ + ì´ì „ í¬ì¦ˆ bbox ì¬ì‚¬ìš© ---\n",
    "import os, re, glob, json, numpy as np, mmcv, cv2\n",
    "from tqdm import tqdm\n",
    "from mmdet.apis import inference_detector\n",
    "from mmpose.apis import inference_topdown\n",
    "from mmpose.evaluation.functional import nms\n",
    "from mmpose.structures import merge_data_samples, split_instances\n",
    "\n",
    "# paths ë”•ì…”ë„ˆë¦¬ì—ì„œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸° (ì• ì…€ì—ì„œ paths ìƒì„±ë˜ì–´ ìˆì–´ì•¼ í•¨)\n",
    "assert 'paths' in globals(), \"ì• ì…€ì—ì„œ pathsë¥¼ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.\"\n",
    "FRAME_DIR = paths[\"FRAME_DIR\"]\n",
    "JSON_DIR  = paths[\"JSON_DIR\"]\n",
    "os.makedirs(JSON_DIR, exist_ok=True)  # JSON ì €ì¥ í´ë” ë³´ì¥\n",
    "\n",
    "def natural_key(s: str):\n",
    "    base = os.path.basename(s)\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.split(r'(\\d+)', base)]\n",
    "\n",
    "all_frames = sorted(\n",
    "    [p for p in glob.glob(os.path.join(FRAME_DIR, \"*\"))\n",
    "     if p.lower().endswith((\".jpg\", \".png\", \".jpeg\"))],\n",
    "    key=natural_key)\n",
    "assert all_frames, f\"ì´ë¯¸ì§€ ì—†ìŒ: {FRAME_DIR}\"\n",
    "frames = all_frames[::2]  # 30fps â†’ 15fps\n",
    "print(f\"ì „ì²´ {len(all_frames)}ì¥ â†’ 15fpsìš© {len(frames)}ì¥ ì„ íƒ\")\n",
    "\n",
    "def to_py(obj):\n",
    "    import numpy as _np\n",
    "    if isinstance(obj, _np.ndarray): return obj.tolist()\n",
    "    if isinstance(obj, (_np.floating,)): return float(obj)\n",
    "    if isinstance(obj, (_np.integer,)):  return int(obj)\n",
    "    if isinstance(obj, dict):  return {k: to_py(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple)): return [to_py(v) for v in obj]\n",
    "    return obj\n",
    "\n",
    "def clip_xyxy(xyxy, w, h):\n",
    "    x1, y1, x2, y2 = xyxy\n",
    "    return [max(0, x1), max(0, y1), min(w - 1, x2), min(h - 1, y2)]\n",
    "\n",
    "def bbox_from_keypoints(kpts, scores, thr=0.3, pad_scale=1.25, img_wh=None):\n",
    "    valid = scores >= thr\n",
    "    if valid.sum() == 0:\n",
    "        return None\n",
    "    xy = kpts[valid]\n",
    "    x1, y1 = xy.min(axis=0)\n",
    "    x2, y2 = xy.max(axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "    w, h = max(2.0, x2 - x1), max(2.0, y2 - y1)\n",
    "    w2, h2 = w * pad_scale / 2, h * pad_scale / 2\n",
    "    bx = [cx - w2, cy - h2, cx + w2, cy + h2]\n",
    "    if img_wh is not None:\n",
    "        bx = clip_xyxy(bx, img_wh[0], img_wh[1])\n",
    "    return bx\n",
    "\n",
    "det_every = 5\n",
    "det_thr   = 0.5\n",
    "nms_thr   = 0.5\n",
    "kpt_thr   = 0.3\n",
    "pad_scale = 1.30\n",
    "miss_max  = 2\n",
    "\n",
    "prev_bbox = None\n",
    "miss_cnt  = 0\n",
    "ok, fail  = 0, 0\n",
    "\n",
    "for i, img_path in enumerate(tqdm(frames)):\n",
    "    try:\n",
    "        img_bgr = cv2.imread(img_path)\n",
    "        if img_bgr is None:\n",
    "            continue\n",
    "        H, W = img_bgr.shape[:2]\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        need_det = (i % det_every == 0) or (prev_bbox is None) or (miss_cnt > miss_max)\n",
    "        if need_det:\n",
    "            det = inference_detector(detector, img_rgb)\n",
    "            pred = det.pred_instances.cpu().numpy()\n",
    "            if len(pred.bboxes):\n",
    "                bbs = np.concatenate((pred.bboxes, pred.scores[:, None]), axis=1)\n",
    "                keep = (pred.labels == 0) & (pred.scores > det_thr)\n",
    "                bbs = bbs[keep]\n",
    "                if len(bbs) > 0:\n",
    "                    bbs = bbs[nms(bbs, nms_thr), :4]\n",
    "                if len(bbs) > 0:\n",
    "                    areas = (bbs[:, 2] - bbs[:, 0]) * (bbs[:, 3] - bbs[:, 1])\n",
    "                    prev_bbox = bbs[np.argmax(areas)].tolist()\n",
    "                    miss_cnt = 0\n",
    "                else:\n",
    "                    prev_bbox = None\n",
    "            else:\n",
    "                prev_bbox = None\n",
    "\n",
    "        bboxes_np = (np.array([prev_bbox], dtype=np.float32)\n",
    "                     if prev_bbox is not None else np.empty((0, 4), dtype=np.float32))\n",
    "\n",
    "        pose_results = inference_topdown(pose_estimator, img_rgb, bboxes_np)\n",
    "        data_sample  = merge_data_samples(pose_results)\n",
    "\n",
    "        inst = data_sample.get('pred_instances', None)\n",
    "        if inst is not None and len(inst.get('keypoints', [])) > 0:\n",
    "            kpts_all    = inst['keypoints']\n",
    "            kscores_all = inst['keypoint_scores']\n",
    "            idx = int(np.argmax(kscores_all.mean(axis=1)))\n",
    "            kpts, kscores = kpts_all[idx], kscores_all[idx]\n",
    "            nb = bbox_from_keypoints(kpts, kscores, thr=kpt_thr, pad_scale=pad_scale, img_wh=(W, H))\n",
    "            if nb is not None:\n",
    "                prev_bbox = nb\n",
    "                miss_cnt = 0\n",
    "            else:\n",
    "                miss_cnt += 1\n",
    "        else:\n",
    "            miss_cnt += 1\n",
    "\n",
    "        # JSON ì €ì¥\n",
    "        if inst is not None:\n",
    "            inst_list = split_instances(inst)\n",
    "            payload = dict(meta_info=pose_estimator.dataset_meta, instance_info=inst_list)\n",
    "            base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            json_path = os.path.join(JSON_DIR, base + \".json\")\n",
    "            with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(to_py(payload), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        ok += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        fail += 1\n",
    "        print(\"ì—ëŸ¬:\", os.path.basename(img_path), \"->\", e)\n",
    "\n",
    "print(f\"ì™„ë£Œ. ì„±ê³µ {ok}, ì‹¤íŒ¨ {fail}, ì¶œë ¥: {JSON_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f78f31-6bdf-4e9e-b743-99b0f4e874b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overlay 30fps:   0% 11/11370 [00:02<44:51,  4.22frame/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m         json_data \u001b[38;5;241m=\u001b[39m last_json_data\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# ì›ë³¸ í”„ë ˆì„ ë¡œë“œ\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m img_bgr \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img_bgr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     skipped \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- 15fps ì˜ˆì¸¡(JSON) â†’ 30fps ì—…ìƒ˜í”Œ: JSON ì €ì¥ ì—†ì´ 'ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€'ë§Œ ì €ì¥ ---\n",
    "import os, re, glob, json            # ê²½ë¡œ/ì •ë ¬/íŒŒì¼ê²€ìƒ‰/JSON\n",
    "import cv2                           # OpenCV (ì´ë¯¸ì§€ ë¡œë“œ/ì €ì¥, ê·¸ë¦¬ê¸°)\n",
    "import numpy as np                   # ìˆ˜ì¹˜ ê³„ì‚°\n",
    "from tqdm import tqdm                # ì§„í–‰ë¥  í‘œì‹œ\n",
    "\n",
    "VIS_DIR=  paths[\"VIS_DIR\"]\n",
    "\n",
    "# ===== ìì—° ì •ë ¬ =====\n",
    "def natural_key(s: str):\n",
    "    base = os.path.basename(s)\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.split(r'(\\d+)', base)]\n",
    "\n",
    "# ===== 30fps ì „ì²´ í”„ë ˆì„ ëª©ë¡ =====\n",
    "all_frames = sorted(\n",
    "    [p for p in glob.glob(os.path.join(FRAME_DIR, \"*\")) if p.lower().endswith((\".jpg\",\".png\",\".jpeg\"))],\n",
    "    key=natural_key\n",
    ")\n",
    "assert all_frames, f\"ì›ë³¸ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤: {FRAME_DIR}\"\n",
    "\n",
    "# ===== 15fps JSON ë§µ =====\n",
    "src_json_files = sorted(glob.glob(os.path.join(JSON_DIR, \"*.json\")), key=natural_key)\n",
    "assert src_json_files, f\"15fps JSONì´ ì—†ìŠµë‹ˆë‹¤: {JSON_DIR}\"\n",
    "src_json_map = {os.path.splitext(os.path.basename(p))[0]: p for p in src_json_files}\n",
    "\n",
    "# ===== ì‹œê°í™” íŒŒë¼ë¯¸í„° (ë‹¨ì¼ ìƒ‰) =====\n",
    "KPT_THR         = 0.05                # í‚¤í¬ì¸íŠ¸ ì‹ ë¢°ë„ ì„ê³„ê°’ (í•„ìš”ì‹œ 0.2~0.3ìœ¼ë¡œ ì˜¬ë ¤ ë…¸ì´ì¦ˆ ì œê±°)\n",
    "KEYPOINT_COLOR  = (0, 255, 0)         # ì  ìƒ‰ (BGR)\n",
    "SKELETON_COLOR  = (255, 128, 0)       # ì„  ìƒ‰ (BGR)\n",
    "RADIUS          = 4                   # ì  ë°˜ì§€ë¦„\n",
    "THICKNESS       = 2                   # ì„  ë‘ê»˜\n",
    "ANTI_ALIAS      = cv2.LINE_AA         # ì•ˆí‹°ì•¨ë¦¬ì–´ì‹±\n",
    "\n",
    "# ===== ìŠ¤ì¼ˆë ˆí†¤ ë§í¬ ì–»ê¸° =====\n",
    "def get_links(meta: dict):\n",
    "    if \"skeleton_links\" in meta:\n",
    "        return meta[\"skeleton_links\"]\n",
    "    if \"skeleton\" in meta:\n",
    "        return meta[\"skeleton\"]\n",
    "    return []\n",
    "\n",
    "# ===== í•œ ì¸ìŠ¤í„´ìŠ¤ ê·¸ë¦¬ê¸° (ë‹¨ì¼ ìƒ‰, bbox X) =====\n",
    "def draw_instance_uniform(img_bgr, instance: dict, links, kpt_thr=0.05):\n",
    "    kpts = np.array(instance[\"keypoints\"], dtype=np.float32)\n",
    "    ksc  = np.array(instance[\"keypoint_scores\"], dtype=np.float32)\n",
    "    # í‚¤í¬ì¸íŠ¸(ì )\n",
    "    for xy, sc in zip(kpts, ksc):\n",
    "        if sc < kpt_thr:\n",
    "            continue\n",
    "        x, y = int(xy[0]), int(xy[1])\n",
    "        cv2.circle(img_bgr, (x, y), RADIUS, KEYPOINT_COLOR, -1, lineType=ANTI_ALIAS)\n",
    "    # ìŠ¤ì¼ˆë ˆí†¤(ì„ )\n",
    "    for link in links:\n",
    "        if isinstance(link, dict) and \"link\" in link:\n",
    "            i, j = link[\"link\"]\n",
    "        elif isinstance(link, (list, tuple)) and len(link) == 2:\n",
    "            i, j = link\n",
    "        else:\n",
    "            continue\n",
    "        if i >= len(kpts) or j >= len(kpts):\n",
    "            continue\n",
    "        if ksc[i] < kpt_thr or ksc[j] < kpt_thr:\n",
    "            continue\n",
    "        p1 = (int(kpts[i][0]), int(kpts[i][1]))\n",
    "        p2 = (int(kpts[j][0]), int(kpts[j][1]))\n",
    "        cv2.line(img_bgr, p1, p2, SKELETON_COLOR, THICKNESS, lineType=ANTI_ALIAS)\n",
    "\n",
    "# ===== ë©”ì¸: 30fps ëª¨ë“  í”„ë ˆì„ì— ëŒ€í•´ ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ì €ì¥ (JSONì€ ì €ì¥í•˜ì§€ ì•ŠìŒ) =====\n",
    "last_json_data = None\n",
    "written_img, skipped = 0, 0\n",
    "\n",
    "for fpath in tqdm(all_frames, desc=\"Overlay 30fps\", unit=\"frame\"):\n",
    "    base = os.path.splitext(os.path.basename(fpath))[0]           # ì˜ˆ: frame_000123\n",
    "    # 15fps JSON ìˆìœ¼ë©´ ë¡œë“œ, ì—†ìœ¼ë©´ ì§ì „ JSONì„ ì‚¬ìš©(Zero-Order Hold)\n",
    "    src_json_path = src_json_map.get(base, None)\n",
    "    if src_json_path is not None:\n",
    "        with open(src_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_data = json.load(f)\n",
    "        last_json_data = json_data\n",
    "    else:\n",
    "        if last_json_data is None:\n",
    "            # (ì´ˆë°˜ë¶€ ì˜ˆì™¸ ì²˜ë¦¬) ì•ìœ¼ë¡œ ë³´ì´ëŠ” ì²« JSON 1íšŒìš© ì‚¬ìš©\n",
    "            next_json_path = None\n",
    "            for nb in sorted(src_json_map.keys(), key=natural_key):\n",
    "                if nb > base:\n",
    "                    next_json_path = src_json_map[nb]\n",
    "                    break\n",
    "            if next_json_path is None:\n",
    "                skipped += 1\n",
    "                continue\n",
    "            with open(next_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                json_data = json.load(f)\n",
    "        else:\n",
    "            json_data = last_json_data\n",
    "\n",
    "    # ì›ë³¸ í”„ë ˆì„ ë¡œë“œ\n",
    "    img_bgr = cv2.imread(fpath)\n",
    "    if img_bgr is None:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    # ìŠ¤ì¼ˆë ˆí†¤/í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸°\n",
    "    meta      = json_data.get(\"meta_info\", {})\n",
    "    instances = json_data.get(\"instance_info\", [])\n",
    "    links     = get_links(meta)\n",
    "    for inst in instances:\n",
    "        draw_instance_uniform(img_bgr, inst, links, kpt_thr=KPT_THR)\n",
    "\n",
    "    # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ì €ì¥\n",
    "    out_img_path = os.path.join(VIS_DIR, base + \".jpg\")\n",
    "    if cv2.imwrite(out_img_path, img_bgr):\n",
    "        written_img += 1\n",
    "    else:\n",
    "        skipped += 1\n",
    "\n",
    "print(f\"ì™„ë£Œ: ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ {written_img}ê°œ ì €ì¥, ìŠ¤í‚µ {skipped}ê°œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e60ff50-be35-4b54-b423-b9b6dd8e17be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ì—…ìƒ˜í”Œëœ 30fps ì‹œê°í™” í”„ë ˆì„ â†’ 30fps MP4 (tqdm ì§„í–‰ë¥ , ì§€ì • ê²½ë¡œ ì €ì¥) ---\n",
    "import os, re, glob, cv2\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "assert 'paths' in globals(), \"ì• ì…€ì—ì„œ pathsë¥¼ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.\"\n",
    "\n",
    "# í”„ë ˆì„ í´ë”(VIS_DIR)ì™€ ì¶œë ¥ íŒŒì¼ ê²½ë¡œ(OUTPUT_MP4)ë¥¼ pathsì—ì„œ ì‚¬ìš©\n",
    "VIS_DIR  = paths[\"VIS_DIR\"]\n",
    "SAVE_MP4 = paths[\"OUTPUT_MP4\"]\n",
    "Path(Path(SAVE_MP4).parent).mkdir(parents=True, exist_ok=True)  # ì¶œë ¥ í´ë” ë³´ì¥\n",
    "\n",
    "def natural_key(s: str):\n",
    "    base = os.path.basename(s)\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.split(r'(\\d+)', base)]\n",
    "\n",
    "# í”„ë ˆì„ ìˆ˜ì§‘ (ìì—° ì •ë ¬)\n",
    "frames = sorted(\n",
    "    [p for p in glob.glob(os.path.join(VIS_DIR, \"*\")) if p.lower().endswith((\".jpg\", \".png\", \".jpeg\"))],\n",
    "    key=natural_key\n",
    ")\n",
    "assert frames, f\"í”„ë ˆì„ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤: {VIS_DIR}\"\n",
    "\n",
    "# ë¹„ë””ì˜¤ ë¼ì´í„° ì´ˆê¸°í™”\n",
    "first = cv2.imread(frames[0])\n",
    "assert first is not None, f\"ì²« í”„ë ˆì„ ë¡œë“œ ì‹¤íŒ¨: {frames[0]}\"\n",
    "h, w = first.shape[:2]\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # í˜¸í™˜ì„± ì¢‹ì€ ì½”ë±\n",
    "writer = cv2.VideoWriter(SAVE_MP4, fourcc, 30, (w, h))\n",
    "\n",
    "# ì¸ì½”ë”© ë£¨í”„ (tqdm ì§„í–‰ë¥ )\n",
    "for f in tqdm(frames, desc=\"Encoding 30fps MP4\", unit=\"frame\"):\n",
    "    img = cv2.imread(f)\n",
    "    if img is None:\n",
    "        print(f\"[ê²½ê³ ] í”„ë ˆì„ ë¡œë“œ ì‹¤íŒ¨: {f}\")\n",
    "        continue\n",
    "    if img.shape[:2] != (h, w):\n",
    "        img = cv2.resize(img, (w, h), interpolation=cv2.INTER_AREA)\n",
    "    writer.write(img)\n",
    "\n",
    "writer.release()\n",
    "print(\"30fps ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ:\", SAVE_MP4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9ee56be-f7b8-41be-823a-d202ca1dd190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/conda/lib/python3.10/site-packages/mmengine/utils/package_utils.py:48: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound, get_distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ“‚ Paths\n",
      "============================================================\n",
      "MP4_PATH     : ../../../../data/ê¹€ì› ë³´ì‚°ì§„ ì—°êµ¬/M01_VISIT2_ìƒì§€.MP4  âœ…\n",
      "FRAME_DIR    : ../data/Patient_data/new_code/frames/M01_VISIT2_ìƒì§€_frame  âœ…\n",
      "JSON_DIR     : ../data/Patient_data/new_code/json/M01_VISIT2_ìƒì§€_json  âœ…\n",
      "VIS_DIR      : ../data/Patient_data/new_code/vis/M01_VISIT2_ìƒì§€_vis  âœ…\n",
      "OUTPUT_MP4   : ../data/Patient_data/new_code/output/M01_VISIT2_ìƒì§€_output.mp4  âœ…\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pass-1â†’FixedBBox:   6% 102/1798 [00:03<00:54, 30.89frame/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 246\u001b[0m\n\u001b[1;32m    244\u001b[0m print_paths(paths)  \u001b[38;5;66;03m# ê²½ë¡œ ìƒíƒœë¥¼ ëˆˆìœ¼ë¡œ í™•ì¸í•  ìˆ˜ ìˆê²Œ ì¶œë ¥í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m yolo \u001b[38;5;241m=\u001b[39m YOLO(YOLO_WEIGHTS)  \u001b[38;5;66;03m# YOLOv8 ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m fixed_box, orig_fps, (W, H), frame_limit \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_fixed_box_fullscan\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ì „ì²´ í”„ë ˆì„ì„ ìŠ¤ìº”í•´ ê³ ì • ë°•ìŠ¤ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.\u001b[39;49;00m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mMP4_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myolo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDURATION_SEC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRESIZE_WIDTH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYOLO_CONF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFIXED_BOX_MARGIN\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# ìŠ¤ìº”ì— ì‚¬ìš©í•  ì„¤ì •ì„ ì „ë‹¬í•©ë‹ˆë‹¤.\u001b[39;49;00m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ê³ ì • ë°•ìŠ¤ ì‚°ì¶œ í˜¸ì¶œì„ ë§ˆì¹©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Fixed BBox (orig): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfixed_box\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# ì›ë³¸ í•´ìƒë„ ê¸°ì¤€ ê³ ì • ë°•ìŠ¤ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m n_written \u001b[38;5;241m=\u001b[39m run_pose_and_render(  \u001b[38;5;66;03m# ìƒ˜í”Œë§ëœ í”„ë ˆì„ë§Œ í¬ì¦ˆ/JSON/ì˜¤ë²„ë ˆì´/ë¹„ë””ì˜¤ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     MP4_PATH, paths, fixed_box, orig_fps, frame_limit, TARGET_FPS, RESIZE_WIDTH, SAVE_FRAMES, SAVE_OVERLAY_IMAGES  \u001b[38;5;66;03m# ë³¸ ì²˜ë¦¬ ì„¤ì •ì„ ì „ë‹¬í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[1;32m    252\u001b[0m )  \u001b[38;5;66;03m# ë³¸ ì²˜ë¦¬ í˜¸ì¶œì„ ë§ˆì¹©ë‹ˆë‹¤.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 164\u001b[0m, in \u001b[0;36mcompute_fixed_box_fullscan\u001b[0;34m(mp4_path, yolo_model, duration_sec, resize_width, conf_thr, margin_ratio)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ok: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# í”„ë ˆì„ì„ ë” ì´ìƒ ì½ì„ ìˆ˜ ì—†ìœ¼ë©´ ë£¨í”„ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m small, sx, sy \u001b[38;5;241m=\u001b[39m resize_keep_w(frame, new_w\u001b[38;5;241m=\u001b[39mresize_width)  \u001b[38;5;66;03m# YOLO ì†ë„/ì¼ê´€ì„±ì„ ìœ„í•´ 720p ìˆ˜ì¤€ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43myolo_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf_thr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# ì‚¬ëŒ í´ë˜ìŠ¤ë§Œ ëŒ€ìƒìœ¼ë¡œ YOLO ê²€ì¶œì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m xyxy \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mxyxy\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mboxes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m4\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# ê²€ì¶œ ê²°ê³¼ë¥¼ ì•ˆì „í•˜ê²Œ numpy ë°°ì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xyxy\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# í•˜ë‚˜ ì´ìƒì˜ ë°•ìŠ¤ê°€ ì¡´ì¬í•˜ë©´\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py:187\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    160\u001b[0m     source: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Path \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    161\u001b[0m     stream: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    163\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m    164\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m    Alias for the predict method, enabling the model instance to be callable for predictions.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;124;03m        ...     print(f\"Detected {len(r)} objects in image\")\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/model.py:557\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[0;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/predictor.py:229\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/predictor.py:332\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 332\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/engine/predictor.py:184\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[0;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    180\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    183\u001b[0m )\n\u001b[0;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/autobackend.py:637\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[0;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[0;32m--> 637\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py:139\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py:157\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[0;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/tasks.py:180\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[0;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[0;32m--> 180\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[1;32m    181\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ultralytics/nn/modules/conv.py:93\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- 15fps ì˜ˆì¸¡(JSON) â†’ 30fps ì—…ìƒ˜í”Œ: 'ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€' ì €ì¥ ì˜µì…˜ + tqdm ì§„í–‰ë¥ ë¡œ ë°”ë¡œ MP4 ì¸ì½”ë”© ---\n",
    "import os, re, glob, json                              # ê²½ë¡œ/ì •ë ¬/íŒŒì¼ê²€ìƒ‰/JSON íŒŒì‹±ì„ ìœ„í•œ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "import cv2                                             # ì´ë¯¸ì§€ ë¡œë“œ/ê·¸ë¦¬ê¸°/ë¹„ë””ì˜¤ ì¸ì½”ë”©ì„ ìœ„í•´ OpenCVë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "import numpy as np                                     # ìˆ˜ì¹˜ ì—°ì‚°ì„ ìœ„í•´ NumPyë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "from tqdm import tqdm                                   # ì§„í–‰ë¥  í‘œì‹œë¥¼ ìœ„í•´ tqdmì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "from pathlib import Path                                # ì¶œë ¥ ë””ë ‰í„°ë¦¬ ë³´ì¥ì„ ìœ„í•´ Pathë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "import time                                            # ì²˜ë¦¬ ì†ë„(FPS) ì¸¡ì •ì„ ìœ„í•´ time ëª¨ë“ˆì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "assert 'paths' in globals(), \"ì• ì…€ì—ì„œ pathsë¥¼ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”.\"  # ìƒìœ„ ì…€ì—ì„œ ê²½ë¡œ ë”•ì…”ë„ˆë¦¬(paths)ê°€ ì •ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "FRAME_DIR = paths[\"FRAME_DIR\"]                         # ì›ë³¸ 30fps í”„ë ˆì„ í´ë” ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "JSON_DIR  = paths[\"JSON_DIR\"]                          # 15fps JSON í´ë” ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "VIS_DIR   = paths[\"VIS_DIR\"]                           # (ì„ íƒ) ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  í´ë” ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "SAVE_MP4  = paths[\"OUTPUT_MP4\"]                        # ìµœì¢… ì¶œë ¥ MP4 íŒŒì¼ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "\n",
    "SAVE_OVERLAY_IMAGES = False                            # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œë„ ì €ì¥í• ì§€ ì—¬ë¶€(False: ì €ì¥ ì•ˆ í•¨, True: ì €ì¥)ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "FPS_OUT = 30                                           # ì¶œë ¥ ë¹„ë””ì˜¤ FPSë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ===== ìì—° ì •ë ¬ ìœ í‹¸ =====\n",
    "def natural_key(s: str):                               # íŒŒì¼ëª…ì„ ì‚¬ëŒ ì¹œí™”ì ìœ¼ë¡œ ì •ë ¬í•˜ê¸° ìœ„í•œ í‚¤ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "    base = os.path.basename(s)                         # ê²½ë¡œì—ì„œ íŒŒì¼ëª…ë§Œ ë¶„ë¦¬í•©ë‹ˆë‹¤.\n",
    "    return [int(t) if t.isdigit() else t.lower()       # ìˆ«ìëŠ” ì •ìˆ˜ë¡œ ë³€í™˜, ë‚˜ë¨¸ì§€ëŠ” ì†Œë¬¸ì ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬\n",
    "            for t in re.split(r'(\\d+)', base)]         # ìˆ«ì/ë¬¸ì ê²½ê³„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬ëœ í† í° ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ===== ìŠ¤ì¼ˆë ˆí†¤ ë§í¬ ì¶”ì¶œ =====\n",
    "def get_links(meta: dict):                             # JSON ë©”íƒ€ ì •ë³´ì—ì„œ ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²° ì •ë³´ë¥¼ ì–»ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "    if \"skeleton_links\" in meta:                       # ìƒˆ í‚¤ ì´ë¦„(skeleton_links)ì´ ì¡´ì¬í•˜ë©´\n",
    "        return meta[\"skeleton_links\"]                  # í•´ë‹¹ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    if \"skeleton\" in meta:                             # êµ¬ í‚¤ ì´ë¦„(skeleton)ì´ ì¡´ì¬í•˜ë©´\n",
    "        return meta[\"skeleton\"]                        # í•´ë‹¹ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    return []                                          # ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ===== ì‹œê°í™” íŒŒë¼ë¯¸í„° (ë‹¨ì¼ ìƒ‰) =====\n",
    "KPT_THR        = 0.05                                  # í‚¤í¬ì¸íŠ¸ ì‹ ë¢°ë„ ì„ê³„ê°’(ë‚®ì€ ì  í•„í„°ë§)ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "KEYPOINT_COLOR = (0, 255, 0)                           # í‚¤í¬ì¸íŠ¸ ì  ìƒ‰ìƒ(BGR, ë…¹ìƒ‰)ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "SKELETON_COLOR = (255, 128, 0)                         # ìŠ¤ì¼ˆë ˆí†¤ ì„  ìƒ‰ìƒ(BGR, ì£¼í™©)ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "RADIUS         = 4                                     # í‚¤í¬ì¸íŠ¸ ì  ë°˜ì§€ë¦„ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "THICKNESS      = 2                                     # ìŠ¤ì¼ˆë ˆí†¤ ì„  ë‘ê»˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "ANTI_ALIAS     = cv2.LINE_AA                           # ì•ˆí‹°ì•¨ë¦¬ì–´ì‹± ë¼ì¸ íƒ€ì…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ===== ë‹¨ì¼ ì¸ìŠ¤í„´ìŠ¤ ì˜¤ë²„ë ˆì´ ê·¸ë¦¬ê¸° =====\n",
    "def draw_instance_uniform(img_bgr, instance: dict, links, kpt_thr=0.05):  # í•œ ì¸ìŠ¤í„´ìŠ¤ì˜ í‚¤í¬ì¸íŠ¸/ìŠ¤ì¼ˆë ˆí†¤ì„ ê·¸ë¦¬ëŠ” í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "    kpts = np.array(instance[\"keypoints\"], dtype=np.float32)               # í‚¤í¬ì¸íŠ¸ ì¢Œí‘œ ë°°ì—´ì„ float32ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    ksc  = np.array(instance[\"keypoint_scores\"], dtype=np.float32)         # í‚¤í¬ì¸íŠ¸ ì‹ ë¢°ë„ ë°°ì—´ì„ float32ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    for xy, sc in zip(kpts, ksc):                                          # ê° í‚¤í¬ì¸íŠ¸ ì¢Œí‘œì™€ ì‹ ë¢°ë„ë¥¼ ìˆœíšŒí•©ë‹ˆë‹¤.\n",
    "        if sc < kpt_thr:                                                   # ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´\n",
    "            continue                                                       # ê·¸ë¦¬ê¸°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\n",
    "        x, y = int(xy[0]), int(xy[1])                                      # ì¢Œí‘œë¥¼ ì •ìˆ˜ í”½ì…€ ê°’ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "        cv2.circle(img_bgr, (x, y), RADIUS, KEYPOINT_COLOR, -1, lineType=ANTI_ALIAS)  # ì±„ì›Œì§„ ì›ìœ¼ë¡œ ì ì„ ê·¸ë¦½ë‹ˆë‹¤.\n",
    "    for link in links:                                                     # ë§í¬ ì •ì˜ë¥¼ ìˆœíšŒí•˜ë©° ì„ ì„ ê·¸ë¦½ë‹ˆë‹¤.\n",
    "        if isinstance(link, dict) and \"link\" in link:                      # ë”•ì…”ë„ˆë¦¬ í˜•íƒœ { \"link\": [i, j] }ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "            i, j = link[\"link\"]                                            # ì¸ë±ìŠ¤ ìŒì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "        elif isinstance(link, (list, tuple)) and len(link) == 2:           # [i, j] ë˜ëŠ” (i, j) í˜•íƒœë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "            i, j = link                                                    # ì¸ë±ìŠ¤ ìŒì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "        else:                                                              # ê·¸ ì™¸ í˜•ì‹ì€\n",
    "            continue                                                       # ë¬´ì‹œí•©ë‹ˆë‹¤.\n",
    "        if i >= len(kpts) or j >= len(kpts):                               # ì¸ë±ìŠ¤ê°€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ë©´\n",
    "            continue                                                       # ê·¸ë¦¬ê¸°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\n",
    "        if ksc[i] < kpt_thr or ksc[j] < kpt_thr:                           # ì—°ê²°ëœ ì  ì¤‘ í•˜ë‚˜ë¼ë„ ì„ê³„ê°’ ë¯¸ë§Œì´ë©´\n",
    "            continue                                                       # ì„ ì„ ê·¸ë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "        p1 = (int(kpts[i][0]), int(kpts[i][1]))                            # ì²« ë²ˆì§¸ ì  ì¢Œí‘œë¥¼ ì •ìˆ˜ë¡œ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "        p2 = (int(kpts[j][0]), int(kpts[j][1]))                            # ë‘ ë²ˆì§¸ ì  ì¢Œí‘œë¥¼ ì •ìˆ˜ë¡œ ì¤€ë¹„í•©ë‹ˆë‹¤.\n",
    "        cv2.line(img_bgr, p1, p2, SKELETON_COLOR, THICKNESS, lineType=ANTI_ALIAS)  # ë‘ ì ì„ ì„ ìœ¼ë¡œ ì—°ê²°í•´ ê·¸ë¦½ë‹ˆë‹¤.\n",
    "\n",
    "# ===== 30fps ì „ì²´ í”„ë ˆì„ ìˆ˜ì§‘ =====\n",
    "all_frames = sorted(                                                       # ëª¨ë“  ì…ë ¥ í”„ë ˆì„ì„ ìì—° ì •ë ¬ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\n",
    "    [p for p in glob.glob(os.path.join(FRAME_DIR, \"*\"))                    # í´ë” ë‚´ ëª¨ë“  í•­ëª© ì¤‘ì—ì„œ\n",
    "     if p.lower().endswith((\".jpg\", \".png\", \".jpeg\"))],                    # ì´ë¯¸ì§€ í™•ì¥ìë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.\n",
    "    key=natural_key                                                        # ìì—° ì •ë ¬ í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    ")\n",
    "assert all_frames, f\"ì›ë³¸ í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤: {FRAME_DIR}\"                   # í”„ë ˆì„ì´ ì—†ìœ¼ë©´ ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ===== 15fps JSON ë§µ êµ¬ì„± =====\n",
    "src_json_files = sorted(                                                   # 15fps JSON íŒŒì¼ ëª©ë¡ì„ ìì—° ì •ë ¬ë¡œ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\n",
    "    glob.glob(os.path.join(JSON_DIR, \"*.json\")),                           # JSON í´ë”ì—ì„œ *.json íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.\n",
    "    key=natural_key                                                        # ìì—° ì •ë ¬ í‚¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    ")\n",
    "assert src_json_files, f\"15fps JSONì´ ì—†ìŠµë‹ˆë‹¤: {JSON_DIR}\"                 # JSONì´ ì—†ìœ¼ë©´ ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\n",
    "src_json_map = {os.path.splitext(os.path.basename(p))[0]: p                # íŒŒì¼ëª…(í™•ì¥ì ì œì™¸)ì„ í‚¤ë¡œ í•˜ê³ \n",
    "                for p in src_json_files}                                   # ì „ì²´ ê²½ë¡œë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "sorted_json_keys = sorted(src_json_map.keys(), key=natural_key)            # ìì—° ì •ë ¬ëœ JSON í‚¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¯¸ë¦¬ ë§Œë“¤ì–´ ë‘¡ë‹ˆë‹¤.\n",
    "\n",
    "# ===== ë¹„ë””ì˜¤ ë¼ì´í„° ì´ˆê¸°í™” =====\n",
    "first_img = cv2.imread(all_frames[0])                                      # ì²« í”„ë ˆì„ì„ ë¡œë“œí•´ í•´ìƒë„ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.\n",
    "assert first_img is not None, f\"ì²« í”„ë ˆì„ ë¡œë“œ ì‹¤íŒ¨: {all_frames[0]}\"     # ì²« í”„ë ˆì„ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\n",
    "H, W = first_img.shape[:2]                                                 # í”„ë ˆì„ì˜ ë†’ì´/ë„ˆë¹„ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "Path(Path(SAVE_MP4).parent).mkdir(parents=True, exist_ok=True)             # ì¶œë ¥ ë¹„ë””ì˜¤ í´ë”ë¥¼ ìƒì„±(ì´ë¯¸ ìˆìœ¼ë©´ ë¬´ì‹œ)í•©ë‹ˆë‹¤.\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")                                   # í˜¸í™˜ì„± ì¢‹ì€ mp4v ì½”ë±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "writer = cv2.VideoWriter(SAVE_MP4, fourcc, FPS_OUT, (W, H))                # ì„¤ì •í•œ FPS/í•´ìƒë„ë¡œ ë¹„ë””ì˜¤ ë¼ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "assert writer.isOpened(), f\"ë¹„ë””ì˜¤ ë¼ì´í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {SAVE_MP4}\"          # ë¼ì´í„°ê°€ ì •ìƒ ì˜¤í”ˆë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ===== ì„ íƒì  ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ ì €ì¥ ì¤€ë¹„ =====\n",
    "if SAVE_OVERLAY_IMAGES:                                                    # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ íŒŒì¼ ì €ì¥ ì˜µì…˜ì´ Trueì¸ ê²½ìš°\n",
    "    Path(VIS_DIR).mkdir(parents=True, exist_ok=True)                       # ì €ì¥ ë””ë ‰í„°ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "# ===== ë©”ì¸ ë£¨í”„: tqdm ì§„í–‰ë¥ ê³¼ í•¨ê»˜ ì˜¤ë²„ë ˆì´ â†’ ì¦‰ì‹œ ì¸ì½”ë”© =====\n",
    "last_json_data = None                                                      # ì§ì „(JSON í™€ë“œ)ì„ ì €ì¥í•  ë³€ìˆ˜ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "written_frames, skipped = 0, 0                                             # ê¸°ë¡ëœ í”„ë ˆì„ ìˆ˜ì™€ ìŠ¤í‚µ ìˆ˜ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "t_start = time.time()                                                      # ì²˜ë¦¬ ì‹œì‘ ì‹œê°ì„ ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "\n",
    "with tqdm(total=len(all_frames),                                           # ì „ì²´ í”„ë ˆì„ ìˆ˜ë¥¼ ì§€ì •í•´ ì§„í–‰ë¥  ë°”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "          desc=\"Overlayâ†’Encode 30fps MP4\",                                 # ì§„í–‰ë¥  ë°” ì„¤ëª…ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "          unit=\"frame\",                                                    # ë‹¨ìœ„ë¥¼ frameìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.\n",
    "          dynamic_ncols=True,                                              # í„°ë¯¸ë„ ë„ˆë¹„ì— ë”°ë¼ ì¹¼ëŸ¼ì„ ë™ì ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.\n",
    "          leave=True) as pbar:                                             # ì™„ë£Œ í›„ì—ë„ ì§„í–‰ë¥  ë°”ë¥¼ ë‚¨ê²¨ë‘¡ë‹ˆë‹¤.\n",
    "    for fpath in all_frames:                                               # ëª¨ë“  í”„ë ˆì„ì„ ìˆœíšŒí•˜ë©° ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "        base = os.path.splitext(os.path.basename(fpath))[0]                # í˜„ì¬ í”„ë ˆì„ì˜ íŒŒì¼ëª…(í™•ì¥ì ì œì™¸)ì„ êµ¬í•©ë‹ˆë‹¤.\n",
    "        src_json_path = src_json_map.get(base, None)                       # ê°™ì€ ì´ë¦„ì˜ 15fps JSONì´ ìˆëŠ”ì§€ ì¡°íšŒí•©ë‹ˆë‹¤.\n",
    "\n",
    "        if src_json_path is not None:                                      # ì¼ì¹˜í•˜ëŠ” JSONì´ ìˆëŠ” ê²½ìš°\n",
    "            with open(src_json_path, \"r\", encoding=\"utf-8\") as f:          # JSON íŒŒì¼ì„ í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ ì—½ë‹ˆë‹¤.\n",
    "                json_data = json.load(f)                                   # JSONì„ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ì½ìŠµë‹ˆë‹¤.\n",
    "            last_json_data = json_data                                     # ìµœê·¼ JSON ìºì‹œë¥¼ ê°±ì‹ í•©ë‹ˆë‹¤.\n",
    "        else:                                                              # ì¼ì¹˜ JSONì´ ì—†ëŠ” ê²½ìš°\n",
    "            if last_json_data is None:                                     # ì•„ì§ ì–´ë–¤ JSONë„ ìºì‹œë˜ì§€ ì•Šì€ ì´ˆê¸° ìƒíƒœë¼ë©´\n",
    "                json_data = None                                           # ì„ì‹œ ë³€ìˆ˜ ì´ˆê¸°ê°’ì„ Noneìœ¼ë¡œ ë‘¡ë‹ˆë‹¤.\n",
    "                for k in sorted_json_keys:                                 # ìì—° ì •ë ¬ëœ í‚¤ë“¤ì„ ìˆœíšŒí•©ë‹ˆë‹¤.\n",
    "                    if natural_key(k) > natural_key(base):                 # í˜„ì¬ í”„ë ˆì„ëª…ë³´ë‹¤ \"ì´í›„\"ì— ì˜¤ëŠ” JSONì„ ì°¾ìŠµë‹ˆë‹¤.\n",
    "                        with open(src_json_map[k], \"r\", encoding=\"utf-8\") as f:  # í•´ë‹¹ JSON íŒŒì¼ì„ ì—½ë‹ˆë‹¤.\n",
    "                            json_data = json.load(f)                        # JSONì„ íŒŒì‹±í•©ë‹ˆë‹¤.\n",
    "                        last_json_data = json_data                          # ìºì‹œë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "                        break                                              # ì²« í›„ë³´ë¥¼ ì°¾ì•˜ìœ¼ë¯€ë¡œ íƒìƒ‰ì„ ì¤‘ì§€í•©ë‹ˆë‹¤.\n",
    "                if json_data is None:                                      # ëê¹Œì§€ ëª» ì°¾ì€ ê²½ìš°(ë¹„ì •ìƒ ì‹œë‚˜ë¦¬ì˜¤)\n",
    "                    skipped += 1                                           # ìŠ¤í‚µ ì¹´ìš´í„°ë¥¼ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.\n",
    "                    pbar.update(1)                                         # ì§„í–‰ë¥  ë°”ë¥¼ í•œ ì¹¸ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "                    pbar.set_postfix(written=written_frames, skipped=skipped)  # í˜„ì¬ ëˆ„ì  í†µê³„ë¥¼ í‘œê¸°í•©ë‹ˆë‹¤.\n",
    "                    continue                                               # ë‹¤ìŒ í”„ë ˆì„ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.\n",
    "            else:                                                          # ì§ì „ JSONì´ ìˆëŠ” ê²½ìš°\n",
    "                json_data = last_json_data                                 # Zero-Order Hold ë°©ì‹ìœ¼ë¡œ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "        img_bgr = cv2.imread(fpath)                                        # í˜„ì¬ í”„ë ˆì„ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "        if img_bgr is None:                                                # ë¡œë“œ ì‹¤íŒ¨ ì‹œ\n",
    "            skipped += 1                                                   # ìŠ¤í‚µ ì¹´ìš´í„°ë¥¼ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.\n",
    "            pbar.update(1)                                                 # ì§„í–‰ë¥  ë°”ë¥¼ í•œ ì¹¸ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "            pbar.set_postfix(written=written_frames, skipped=skipped)      # í˜„ì¬ ëˆ„ì  í†µê³„ë¥¼ í‘œê¸°í•©ë‹ˆë‹¤.\n",
    "            continue                                                       # ë‹¤ìŒ í”„ë ˆì„ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.\n",
    "\n",
    "        if img_bgr.shape[:2] != (H, W):                                    # í”„ë ˆì„ í•´ìƒë„ê°€ ê¸°ì¤€ê³¼ ë‹¤ë¥´ë©´\n",
    "            img_bgr = cv2.resize(img_bgr, (W, H), interpolation=cv2.INTER_AREA)  # ë¹„ë””ì˜¤ í•´ìƒë„ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆí•©ë‹ˆë‹¤.\n",
    "\n",
    "        meta      = json_data.get(\"meta_info\", {})                         # ë©”íƒ€ ì •ë³´ë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "        instances = json_data.get(\"instance_info\", [])                     # ì¸ìŠ¤í„´ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "        links     = get_links(meta)                                        # ìŠ¤ì¼ˆë ˆí†¤ ë§í¬ ì •ë³´ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "        for inst in instances:                                             # ê° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìˆœíšŒí•˜ë©°\n",
    "            draw_instance_uniform(img_bgr, inst, links, kpt_thr=KPT_THR)   # í‚¤í¬ì¸íŠ¸ì™€ ìŠ¤ì¼ˆë ˆí†¤ì„ ë‹¨ì¼ ìƒ‰ìœ¼ë¡œ ê·¸ë¦½ë‹ˆë‹¤.\n",
    "\n",
    "        writer.write(img_bgr)                                              # ê·¸ë ¤ì§„ í”„ë ˆì„ì„ ì¦‰ì‹œ ë¹„ë””ì˜¤ì— ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "        written_frames += 1                                                # ê¸°ë¡ëœ í”„ë ˆì„ ìˆ˜ë¥¼ ê°±ì‹ í•©ë‹ˆë‹¤.\n",
    "\n",
    "        if SAVE_OVERLAY_IMAGES:                                            # ì´ë¯¸ì§€ ì €ì¥ ì˜µì…˜ì´ í™œì„±í™”ë˜ì—ˆë‹¤ë©´\n",
    "            out_img_path = os.path.join(VIS_DIR, base + \".jpg\")            # ì €ì¥ ê²½ë¡œë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "            _ = cv2.imwrite(out_img_path, img_bgr)                         # ì˜¤ë²„ë ˆì´ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "        elapsed = time.time() - t_start                                    # ê²½ê³¼ ì‹œê°„ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "        fps_now = written_frames / max(elapsed, 1e-6)                      # í‰ê·  ì²˜ë¦¬ FPSë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "        pbar.update(1)                                                     # ì§„í–‰ë¥  ë°”ë¥¼ í•œ ì¹¸ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "        pbar.set_postfix(written=written_frames, skipped=skipped, fps=f\"{fps_now:0.2f}\")  # í†µê³„(FPS í¬í•¨)ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.\n",
    "\n",
    "writer.release()                                                            # ë¹„ë””ì˜¤ ë¼ì´í„°ë¥¼ ë‹«ì•„ íŒŒì¼ì„ ì™„ë£Œí•©ë‹ˆë‹¤.\n",
    "total_sec = max(time.time() - t_start, 1e-6)                                # ì´ ê²½ê³¼ ì‹œê°„ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "avg_fps = written_frames / total_sec                                        # ì „ì²´ í‰ê·  FPSë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "print(f\"ì™„ë£Œ: ë¹„ë””ì˜¤ ì €ì¥ {SAVE_MP4}, í”„ë ˆì„ {written_frames}ê°œ ê¸°ë¡, ìŠ¤í‚µ {skipped}ê°œ, í‰ê·  FPS {avg_fps:0.2f}\")  # ì²˜ë¦¬ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sapiens)",
   "language": "python",
   "name": "sapiens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
