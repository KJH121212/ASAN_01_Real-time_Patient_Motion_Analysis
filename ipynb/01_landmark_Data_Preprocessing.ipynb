{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eeaadf4",
   "metadata": {},
   "source": [
    "# DATA Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f5c7b",
   "metadata": {},
   "source": [
    "## DATA DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DIR = \"/workspace/nas203/ds_RehabilitationMedicineData/data/body_key_point_Public_Data\"\n",
    "SAVE_DIR = \"./data/Public_data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df4c82",
   "metadata": {},
   "source": [
    "# ë¼ë²¨ë§ ë³€ê²½í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7746ff",
   "metadata": {},
   "source": [
    "## COCO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ea0ce",
   "metadata": {},
   "source": [
    "### Data Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e93f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_IMG_DIR = {s: os.path.join(BASE_DIR, \"COCO\", s) for s in [\"train2017\", \"val2017\", \"test2017\"]}\n",
    "COCO_ANN_DIR = os.path.join(BASE_DIR, \"COCO\", \"annotations\")  # ì£¼ì„ í´ë”\n",
    "COCO_ANN_FILES  = {  # ì£¼ì„ íŒŒì¼ë§µ\n",
    "    \"train\": os.path.join(COCO_ANN_DIR, \"person_keypoints_train2017.json\"),  # í•™ìŠµ ì£¼ì„\n",
    "    \"val\"  : os.path.join(COCO_ANN_DIR, \"person_keypoints_val2017.json\"),  # ê²€ì¦ ì£¼ì„\n",
    "}\n",
    "COCO_SAVE_DIR = os.path.join(SAVE_DIR,\"COCO\") # COCO ì´ë¯¸ì§€ ë° ë¼ë²¨ ì €ì¥ ë£¨íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94e7a45",
   "metadata": {},
   "source": [
    "### LANDMARK5 ìƒì„± ë° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, shutil  # í‘œì¤€/ì…ì¶œë ¥\n",
    "from collections import defaultdict  # ë”•íŠ¸ ê¸°ë³¸ê°’\n",
    "from tqdm import tqdm  # ì§„í–‰ë°”\n",
    "\n",
    "# ========== ë³€í™˜ ==========  # ë³€í™˜ ë£¨í”„\n",
    "for split, ann_path in COCO_ANN_FILES.items():  # ë¶„í• ë³„ ìˆœíšŒ\n",
    "    print(f\"\\n[{split.upper()}] ë³€í™˜ ì‹œì‘ â–¶\")  # ì§„í–‰ ì¶œë ¥\n",
    "    with open(ann_path, \"r\") as f:  # ì£¼ì„ ì—´ê¸°\n",
    "        coco = json.load(f)  # JSON ë¡œë“œ\n",
    "\n",
    "    images = {img[\"id\"]: img for img in coco[\"images\"]}  # ì´ë¯¸ì§€ ì¸ë±ìŠ¤\n",
    "    labels_dict = defaultdict(list)  # ë¼ë²¨ ëˆ„ì \n",
    "\n",
    "    # --- 1) annotation íŒŒì‹± ---  # íŒŒì‹± ì„¹ì…˜\n",
    "    for ann in tqdm(coco[\"annotations\"], desc=f\"{split}: parse anns\", total=len(coco[\"annotations\"])):  # ì£¼ì„ ìˆœíšŒ\n",
    "        if ann[\"num_keypoints\"] == 0:  # í‚¤í¬ì¸íŠ¸ ì—†ìŒ\n",
    "            continue  # ê±´ë„ˆë›°ê¸°\n",
    "\n",
    "        img_id  = ann[\"image_id\"]  # ì´ë¯¸ì§€ ID\n",
    "        imginfo = images[img_id]  # ì´ë¯¸ì§€ ì •ë³´\n",
    "        W, H    = imginfo[\"width\"], imginfo[\"height\"]  # í­ê³¼ ë†’ì´\n",
    "        if W == 0 or H == 0:  # ìœ íš¨ í¬ê¸° í™•ì¸\n",
    "            continue  # ê±´ë„ˆë›°ê¸°\n",
    "\n",
    "        bx, by, bw, bh = ann[\"bbox\"]  # BBox ì¶”ì¶œ\n",
    "        xc = (bx + bw / 2) / W  # cx ì •ê·œí™”\n",
    "        yc = (by + bh / 2) / H  # cy ì •ê·œí™”\n",
    "        bw /= W  # w ì •ê·œí™”\n",
    "        bh /= H  # h ì •ê·œí™”\n",
    "\n",
    "        kpts = ann[\"keypoints\"]  # í‚¤í¬ì¸íŠ¸ ë°°ì—´\n",
    "        if len(kpts) < 51:  # 17ì *3 ê²€ì¦\n",
    "            continue  # ê±´ë„ˆë›°ê¸°\n",
    "\n",
    "        # --- neck ê³„ì‚° ---  # ëª©ì  ê³„ì‚°\n",
    "        LS, RS = 5, 6  # ì–´ê¹¨ ì¸ë±ìŠ¤\n",
    "        x1, y1, v1 = kpts[LS*3], kpts[LS*3+1], kpts[LS*3+2]  # ì¢Œì¸¡ ì–´ê¹¨\n",
    "        x2, y2, v2 = kpts[RS*3], kpts[RS*3+1], kpts[RS*3+2]  # ìš°ì¸¡ ì–´ê¹¨\n",
    "        nx = (x1 + x2) / 2 / W  # ëª© x ì •ê·œí™”\n",
    "        ny = (y1 + y2) / 2 / H  # ëª© y ì •ê·œí™”\n",
    "        nv = float(min(v1, v2))  # ëª© ê°€ì‹œì„±\n",
    "\n",
    "        reduced_kpts = [nx, ny, nv]  # ì¶•ì•½ í‚¤í¬ì¸íŠ¸ ì‹œì‘\n",
    "\n",
    "        # --- LW(9), RW(10), LA(15), RA(16) ---  # ì„ íƒì  ì¶”ê°€\n",
    "        for idx in [9, 10, 15, 16]:  # ì¸ë±ìŠ¤ ìˆœíšŒ\n",
    "            x, y, v = kpts[idx * 3], kpts[idx * 3 + 1], kpts[idx * 3 + 2]  # ì¢Œí‘œ/ê°€ì‹œì„±\n",
    "            reduced_kpts += [x / W, y / H, float(v)]  # ì •ê·œí™” ì¶”ê°€\n",
    "\n",
    "        # ëª¨ë“  keypointê°€ ê°€ë ¤ì¡Œìœ¼ë©´ skip  # ì „ë¶€ ê°€ë¦¼ ì‹œ ìŠ¤í‚µ\n",
    "        if all(v == 0 for v in reduced_kpts[2::3]):  # ê°€ì‹œì„± ê²€ì‚¬\n",
    "            continue  # ê±´ë„ˆë›°ê¸°\n",
    "\n",
    "        line = [0, xc, yc, bw, bh] + reduced_kpts  # ë¼ë²¨ í•œ ì¤„\n",
    "        labels_dict[img_id].append(' '.join(f\"{x:.6f}\" for x in line))  # í¬ë§· ì €ì¥\n",
    "\n",
    "    # --- 2) ë””ë ‰í„°ë¦¬ ì¤€ë¹„ ---  # ì¶œë ¥ ê²½ë¡œ ì¤€ë¹„\n",
    "    img_out_dir = os.path.join(COCO_SAVE_DIR, split, \"images\")  # ì´ë¯¸ì§€ ì¶œë ¥\n",
    "    lbl_out_dir = os.path.join(COCO_SAVE_DIR, split, \"labels5\")  # ë¼ë²¨ ì¶œë ¥\n",
    "    os.makedirs(img_out_dir, exist_ok=True)  # í´ë” ìƒì„±\n",
    "    os.makedirs(lbl_out_dir, exist_ok=True)  # í´ë” ìƒì„±\n",
    "\n",
    "    # --- 3) ì´ë¯¸ì§€ & ë¼ë²¨ ì €ì¥ ---  # ì €ì¥ ì„¹ì…˜\n",
    "    for img_id, label_lines in tqdm(labels_dict.items(), desc=f\"{split}: save files\", total=len(labels_dict)):  # íŒŒì¼ ìˆœíšŒ\n",
    "        file_name = images[img_id][\"file_name\"]  # íŒŒì¼ëª…\n",
    "        src_path  = os.path.join(COCO_IMG_DIR[f\"{split}2017\"], file_name)  # ì›ë³¸ ê²½ë¡œ\n",
    "        dst_img   = os.path.join(img_out_dir, file_name)  # ëŒ€ìƒ ì´ë¯¸ì§€\n",
    "        dst_lbl   = os.path.join(lbl_out_dir, os.path.splitext(file_name)[0] + \".txt\")  # ëŒ€ìƒ ë¼ë²¨\n",
    "\n",
    "        if not os.path.exists(src_path):  # ì›ë³¸ í™•ì¸\n",
    "            continue  # ê±´ë„ˆë›°ê¸°\n",
    "        shutil.copy2(src_path, dst_img)  # ì´ë¯¸ì§€ ë³µì‚¬\n",
    "\n",
    "        with open(dst_lbl, \"w\") as f:  # ë¼ë²¨ ì“°ê¸°\n",
    "            f.write(\"\\n\".join(label_lines) + \"\\n\")  # ë¼ë²¨ ì €ì¥\n",
    "\n",
    "    print(f\"âœ… {split} ì™„ë£Œ: {len(labels_dict)} images / {sum(len(v) for v in labels_dict.values())} persons\")  # ìš”ì•½ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6412f0f-ca50-462d-ab1a-bf70abed0851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] images: 55,424 | labels: 55,424\n",
      "    â”œâ”€ ë¼ë²¨ ì—†ëŠ” ì´ë¯¸ì§€: 0\n",
      "    â””â”€ ì´ë¯¸ì§€ ì—†ëŠ” ë¼ë²¨: 0\n",
      "[val] images: 2,293 | labels: 2,293\n",
      "    â”œâ”€ ë¼ë²¨ ì—†ëŠ” ì´ë¯¸ì§€: 0\n",
      "    â””â”€ ì´ë¯¸ì§€ ì—†ëŠ” ë¼ë²¨: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- 1) íŠ¹ì • êµ¬ì¡°(COCO) ì¹´ìš´íŠ¸ ----\n",
    "SAVE_BASE = \"./data/Public_data/COCO\"\n",
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    img_dir = os.path.join(SAVE_BASE, split, \"images\")\n",
    "    lbl_dir = os.path.join(SAVE_BASE, split, \"labels5\")\n",
    "\n",
    "    img_count = sum(1 for f in os.listdir(img_dir)\n",
    "                    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")))\n",
    "    lbl_count = sum(1 for f in os.listdir(lbl_dir) if f.lower().endswith(\".txt\"))\n",
    "\n",
    "    # ì´ë¯¸ì§€-ë¼ë²¨ ë§¤ì¹­ ìƒíƒœë„ í•¨ê»˜ ì²´í¬\n",
    "    img_stems = {os.path.splitext(f)[0] for f in os.listdir(img_dir)\n",
    "                 if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))}\n",
    "    lbl_stems = {os.path.splitext(f)[0] for f in os.listdir(lbl_dir)\n",
    "                 if f.lower().endswith(\".txt\")}\n",
    "    missing_lbl = img_stems - lbl_stems\n",
    "    missing_img = lbl_stems - img_stems\n",
    "\n",
    "    print(f\"[{split}] images: {img_count:,} | labels: {lbl_count:,}\")\n",
    "    print(f\"    â”œâ”€ ë¼ë²¨ ì—†ëŠ” ì´ë¯¸ì§€: {len(missing_lbl):,}\")\n",
    "    print(f\"    â””â”€ ì´ë¯¸ì§€ ì—†ëŠ” ë¼ë²¨: {len(missing_img):,}\")\n",
    "\n",
    "# ---- 2) ë²”ìš©: ì„ì˜ í´ë”ì˜ íŒŒì¼ ê°œìˆ˜(í™•ì¥ì/ì¬ê·€ ì˜µì…˜) ----\n",
    "def count_files(dirpath, exts=None, recursive=True):\n",
    "    \"\"\"\n",
    "    dirpath: í´ë” ê²½ë¡œ\n",
    "    exts: ('jpg','png','txt') ì²˜ëŸ¼ í™•ì¥ì íŠœí”Œ/ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì „ì²´)\n",
    "    recursive: í•˜ìœ„ í´ë”ê¹Œì§€ í¬í•¨ ì—¬ë¶€\n",
    "    \"\"\"\n",
    "    dirpath = Path(dirpath)\n",
    "    if exts:\n",
    "        exts = tuple(x.lower().lstrip(\".\") for x in exts)\n",
    "\n",
    "    n = 0\n",
    "    it = dirpath.rglob(\"*\") if recursive else dirpath.iterdir()\n",
    "    for p in it:\n",
    "        if p.is_file():\n",
    "            if not exts:\n",
    "                n += 1\n",
    "            else:\n",
    "                if p.suffix.lower().lstrip(\".\") in exts:\n",
    "                    n += 1\n",
    "    return n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf60f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 180  # ì„ ëª…ë„ ì—…\n",
    "\n",
    "base_dir  = \"./data/Public_data/COCO\"\n",
    "split = \"val\"\n",
    "img_dir = os.path.join(base_dir, split, \"images\")\n",
    "label_dir = os.path.join(base_dir, split, \"labels5\")\n",
    "\n",
    "all_labels = [f for f in os.listdir(label_dir) if f.endswith(\".txt\")]\n",
    "sample_labels = random.sample(all_labels, min(5, len(all_labels)))\n",
    "\n",
    "def find_image_path(root, stem):\n",
    "    for ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        p = os.path.join(root, stem + ext)\n",
    "        if os.path.isfile(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def kpts_to_pixels_image_norm(kpts, w, h):\n",
    "    pts = []\n",
    "    for i in range(0, len(kpts), 3):\n",
    "        x, y, v = kpts[i:i+3]\n",
    "        pts.append((int(x * w), int(y * h), v))\n",
    "    return pts\n",
    "\n",
    "def kpts_to_pixels_box_norm(kpts, xc, yc, bw, bh, w, h):\n",
    "    x0 = (xc - bw / 2.0) * w\n",
    "    y0 = (yc - bh / 2.0) * h\n",
    "    bw_px = bw * w\n",
    "    bh_px = bh * h\n",
    "    pts = []\n",
    "    for i in range(0, len(kpts), 3):\n",
    "        xr, yr, v = kpts[i:i+3]\n",
    "        x = int(x0 + xr * bw_px)\n",
    "        y = int(y0 + yr * bh_px)\n",
    "        pts.append((x, y, v))\n",
    "    return pts\n",
    "\n",
    "def choose_projection(kpts, xc, yc, bw, bh, w, h):\n",
    "    pts_img = kpts_to_pixels_image_norm(kpts, w, h)\n",
    "    pts_box = kpts_to_pixels_box_norm(kpts, xc, yc, bw, bh, w, h)\n",
    "\n",
    "    def in_bound_ratio(pts):\n",
    "        if not pts: return 0.0\n",
    "        cnt = sum(1 for x,y,v in pts if 0 <= x < w and 0 <= y < h and v > 0)\n",
    "        return cnt / (len(pts) or 1)\n",
    "\n",
    "    return pts_img if in_bound_ratio(pts_img) >= in_bound_ratio(pts_box) else pts_box\n",
    "\n",
    "def draw_keypoints_with_ids(image, pts, color=(0, 255, 0)):\n",
    "    for idx, (x, y, v) in enumerate(pts, start=1):\n",
    "        if v <= 0:\n",
    "            continue\n",
    "        cv2.circle(image, (x, y), 8, color, -1, lineType=cv2.LINE_AA)  # ì  ë” í¼\n",
    "        label = str(idx)\n",
    "        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)  # ê¸€ì”¨ ë” í¼\n",
    "        bg_tl = (x + 10, y - th - 8)\n",
    "        bg_br = (x + 10 + tw + 8, y - 2)\n",
    "        cv2.rectangle(image, bg_tl, bg_br, (0, 0, 0), thickness=-1)\n",
    "        cv2.putText(image, label, (x + 14, y - 6),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "palette = [\n",
    "    (0,255,0), (255,0,0), (0,200,255), (255,140,0), (200,0,200),\n",
    "    (255,255,0), (0,255,255), (255,105,180)\n",
    "]\n",
    "\n",
    "for i, lbl_file in enumerate(sample_labels):\n",
    "    stem = os.path.splitext(lbl_file)[0]\n",
    "    img_path = find_image_path(img_dir, stem)\n",
    "    if img_path is None:\n",
    "        print(f\"[ê²½ê³ ] {stem} ì´ë¯¸ì§€ ì—†ìŒ\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    with open(os.path.join(label_dir, lbl_file), \"r\") as f:\n",
    "        for li, line in enumerate(f):\n",
    "            vals = list(map(float, line.strip().split()))\n",
    "            if len(vals) < 5 + 3:\n",
    "                continue\n",
    "            cls, xc, yc, bw, bh = vals[:5]\n",
    "            kpts = vals[5:]\n",
    "            pts = choose_projection(kpts, xc, yc, bw, bh, w, h)\n",
    "            color = palette[li % len(palette)]\n",
    "            img = draw_keypoints_with_ids(img, pts, color=color)\n",
    "\n",
    "    # â˜… í•œ ì¥ì”© í¬ê²Œ í‘œì‹œ\n",
    "    plt.figure(figsize=(4, 3))  # ë” í¬ê²Œ ë³´ê³  ì‹¶ìœ¼ë©´ (20, 15) ë“±ìœ¼ë¡œ ì¡°ì •\n",
    "    plt.imshow(img)\n",
    "    plt.title(os.path.basename(img_path), fontsize=16)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ae277d",
   "metadata": {},
   "source": [
    "## DWPOSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1c82f3",
   "metadata": {},
   "source": [
    "### data dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c907743f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DW_IMG_DIR= os.path.join(BASE_DIR, \"DWPOSE\", \"yolo_format\")\n",
    "DW_SAVE_DIR = os.path.join(SAVE_DIR,\"DWPOSE\") # COCO ì´ë¯¸ì§€ ë° ë¼ë²¨ ì €ì¥ ë£¨íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4769c8fa",
   "metadata": {},
   "source": [
    "### landmark5 ìƒì„± ë° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8d6a7-159e-4973-9b17-92528005344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# DWPOSE ê¸°ì¤€ ë¹¨ê°„ ì  keypoint ì¸ë±ìŠ¤ (ëª©, ì–‘ ì†ëª©, ì–‘ ë°œëª©)\n",
    "keypoint_idxs = [13, 4, 5, 10, 11]\n",
    "\n",
    "IMG_EXTS = [\".jpg\", \".jpeg\", \".png\", \".JPG\", \".JPEG\", \".PNG\"]\n",
    "\n",
    "def find_image_path(img_root, stem):\n",
    "    for ext in IMG_EXTS:\n",
    "        p = os.path.join(img_root, stem + ext)\n",
    "        if os.path.isfile(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    print(f\"â–¶ {split} ì„¸íŠ¸ ë³€í™˜ ì¤‘...\")\n",
    "\n",
    "    original_lbl_dir   = os.path.join(DW_IMG_DIR, split, \"labels\")\n",
    "    original_img_dir   = os.path.join(DW_IMG_DIR, split, \"images\")\n",
    "    reduced_lbl_dir    = os.path.join(DW_SAVE_DIR, split, \"labels5\")\n",
    "    reduced_image_dir  = os.path.join(DW_SAVE_DIR, split, \"images\")\n",
    "\n",
    "    os.makedirs(reduced_lbl_dir, exist_ok=True)\n",
    "    os.makedirs(reduced_image_dir, exist_ok=True)\n",
    "\n",
    "    label_files = sorted([f for f in os.listdir(original_lbl_dir) if f.endswith(\".txt\")])\n",
    "    file_count, line_count, img_count = 0, 0, 0\n",
    "\n",
    "    # tqdm ì ìš©\n",
    "    for fname in tqdm(label_files, desc=f\"{split} ë³€í™˜ ì§„í–‰\"):\n",
    "        input_path  = os.path.join(original_lbl_dir, fname)\n",
    "        output_path = os.path.join(reduced_lbl_dir, fname)\n",
    "\n",
    "        lines_out = []\n",
    "        with open(input_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                vals = list(map(float, line.strip().split()))\n",
    "                if len(vals) < 5 + 3 * (max(keypoint_idxs) + 1):\n",
    "                    continue\n",
    "\n",
    "                cls, xc, yc, bw, bh = vals[:5]\n",
    "                kpts = vals[5:]\n",
    "\n",
    "                # ëª¨ë“  keypoint ê°€ë ¤ì§„ ê²½ìš° skip\n",
    "                visibility = [kpts[idx * 3 + 2] for idx in keypoint_idxs]\n",
    "                if all(v == 0 for v in visibility):\n",
    "                    continue\n",
    "\n",
    "                reduced_kpts = []\n",
    "                for idx in keypoint_idxs:\n",
    "                    reduced_kpts.extend(kpts[idx * 3 : idx * 3 + 3])  # [x, y, v]\n",
    "\n",
    "                new_line = [cls, xc, yc, bw, bh] + reduced_kpts\n",
    "                lines_out.append(' '.join(f\"{v:.6f}\" for v in new_line))\n",
    "\n",
    "        # ë³€í™˜ëœ ë¼ì¸ ìˆìœ¼ë©´ ì €ì¥ + ì´ë¯¸ì§€ ë³µì‚¬\n",
    "        if lines_out:\n",
    "            # 1) ë¼ë²¨ ì €ì¥\n",
    "            with open(output_path, 'w') as fw:\n",
    "                fw.write('\\n'.join(lines_out) + '\\n')\n",
    "            file_count += 1\n",
    "            line_count += len(lines_out)\n",
    "\n",
    "            # 2) ì´ë¯¸ì§€ ë³µì‚¬(í™•ì¥ì ìë™ íƒìƒ‰)\n",
    "            stem = os.path.splitext(fname)[0]\n",
    "            src_img = find_image_path(original_img_dir, stem)\n",
    "            if src_img is not None:\n",
    "                dst_img = os.path.join(reduced_image_dir, os.path.basename(src_img))\n",
    "                # ë³µì‚¬(ë©”íƒ€ë°ì´í„° ë³´ì¡´). ìš©ëŸ‰ ì•„ë¼ë ¤ë©´ os.symlink ì‚¬ìš© ê°€ëŠ¥(íŒŒì¼ì‹œìŠ¤í…œ/ê¶Œí•œ í—ˆìš© ì‹œ)\n",
    "                shutil.copy2(src_img, dst_img)\n",
    "                img_count += 1\n",
    "            else:\n",
    "                # ì´ë¯¸ì§€ê°€ ì—†ì„ ìˆ˜ë„ ìˆìœ¼ë‹ˆ ê²½ê³ ë§Œ í‘œì‹œ\n",
    "                print(f\"[ê²½ê³ ] ì´ë¯¸ì§€ ì—†ìŒ: {stem} (labels OK)\")\n",
    "\n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ: {reduced_lbl_dir} (ë¼ë²¨ íŒŒì¼ {file_count}ê°œ, ë¼ì¸ {line_count}ê°œ)\")\n",
    "    print(f\"âœ… ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ: {reduced_image_dir} (ì´ë¯¸ì§€ {img_count}ê°œ)\")\n",
    "\n",
    "print(\"\\nğŸ‰ ì „ì²´ ë¼ë²¨5 + ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e746900-c724-4fff-a36c-1d18b3ea8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- 1) íŠ¹ì • êµ¬ì¡°(COCO) ì¹´ìš´íŠ¸ ----\n",
    "SAVE_BASE = \"./data/Public_data/DWPOSE\"\n",
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    img_dir = os.path.join(SAVE_BASE, split, \"images\")\n",
    "    lbl_dir = os.path.join(SAVE_BASE, split, \"labels5\")\n",
    "\n",
    "    img_count = sum(1 for f in os.listdir(img_dir)\n",
    "                    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")))\n",
    "    lbl_count = sum(1 for f in os.listdir(lbl_dir) if f.lower().endswith(\".txt\"))\n",
    "\n",
    "    # ì´ë¯¸ì§€-ë¼ë²¨ ë§¤ì¹­ ìƒíƒœë„ í•¨ê»˜ ì²´í¬\n",
    "    img_stems = {os.path.splitext(f)[0] for f in os.listdir(img_dir)\n",
    "                 if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))}\n",
    "    lbl_stems = {os.path.splitext(f)[0] for f in os.listdir(lbl_dir)\n",
    "                 if f.lower().endswith(\".txt\")}\n",
    "    missing_lbl = img_stems - lbl_stems\n",
    "    missing_img = lbl_stems - img_stems\n",
    "\n",
    "    print(f\"[{split}] images: {img_count:,} | labels: {lbl_count:,}\")\n",
    "    print(f\"    â”œâ”€ ë¼ë²¨ ì—†ëŠ” ì´ë¯¸ì§€: {len(missing_lbl):,}\")\n",
    "    print(f\"    â””â”€ ì´ë¯¸ì§€ ì—†ëŠ” ë¼ë²¨: {len(missing_img):,}\")\n",
    "\n",
    "# ---- 2) ë²”ìš©: ì„ì˜ í´ë”ì˜ íŒŒì¼ ê°œìˆ˜(í™•ì¥ì/ì¬ê·€ ì˜µì…˜) ----\n",
    "def count_files(dirpath, exts=None, recursive=True):\n",
    "    \"\"\"\n",
    "    dirpath: í´ë” ê²½ë¡œ\n",
    "    exts: ('jpg','png','txt') ì²˜ëŸ¼ í™•ì¥ì íŠœí”Œ/ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì „ì²´)\n",
    "    recursive: í•˜ìœ„ í´ë”ê¹Œì§€ í¬í•¨ ì—¬ë¶€\n",
    "    \"\"\"\n",
    "    dirpath = Path(dirpath)\n",
    "    if exts:\n",
    "        exts = tuple(x.lower().lstrip(\".\") for x in exts)\n",
    "\n",
    "    n = 0\n",
    "    it = dirpath.rglob(\"*\") if recursive else dirpath.iterdir()\n",
    "    for p in it:\n",
    "        if p.is_file():\n",
    "            if not exts:\n",
    "                n += 1\n",
    "            else:\n",
    "                if p.suffix.lower().lstrip(\".\") in exts:\n",
    "                    n += 1\n",
    "    return n\n",
    "\n",
    "# # ì‚¬ìš© ì˜ˆì‹œ(ì›í•˜ë©´ ì£¼ì„ í•´ì œí•´ì„œ ì‹¤í–‰):\n",
    "# print(count_files(\"/some/path\"))                         # ì „ì²´ íŒŒì¼(ì¬ê·€)\n",
    "# print(count_files(\"/some/path\", exts=[\"jpg\",\"png\"]))     # ì´ë¯¸ì§€ ê°œìˆ˜\n",
    "# print(count_files(\"/some/path\", exts=[\"txt\"], recursive=False))  # í˜„ì¬ í´ë” txt ê°œìˆ˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d3395f-8af1-4fef-8095-04457528d41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 180  # ì„ ëª…ë„ ì—…\n",
    "\n",
    "split = \"val\"\n",
    "img_dir = os.path.join(DW_SAVE_DIR, split, \"images\")\n",
    "label_dir = os.path.join(DW_SAVE_DIR, split, \"labels5\")\n",
    "\n",
    "all_labels = [f for f in os.listdir(label_dir) if f.endswith(\".txt\")]\n",
    "sample_labels = random.sample(all_labels, min(5, len(all_labels)))\n",
    "\n",
    "def find_image_path(root, stem):\n",
    "    for ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        p = os.path.join(root, stem + ext)\n",
    "        if os.path.isfile(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def kpts_to_pixels_image_norm(kpts, w, h):\n",
    "    pts = []\n",
    "    for i in range(0, len(kpts), 3):\n",
    "        x, y, v = kpts[i:i+3]\n",
    "        pts.append((int(x * w), int(y * h), v))\n",
    "    return pts\n",
    "\n",
    "def kpts_to_pixels_box_norm(kpts, xc, yc, bw, bh, w, h):\n",
    "    x0 = (xc - bw / 2.0) * w\n",
    "    y0 = (yc - bh / 2.0) * h\n",
    "    bw_px = bw * w\n",
    "    bh_px = bh * h\n",
    "    pts = []\n",
    "    for i in range(0, len(kpts), 3):\n",
    "        xr, yr, v = kpts[i:i+3]\n",
    "        x = int(x0 + xr * bw_px)\n",
    "        y = int(y0 + yr * bh_px)\n",
    "        pts.append((x, y, v))\n",
    "    return pts\n",
    "\n",
    "def choose_projection(kpts, xc, yc, bw, bh, w, h):\n",
    "    pts_img = kpts_to_pixels_image_norm(kpts, w, h)\n",
    "    pts_box = kpts_to_pixels_box_norm(kpts, xc, yc, bw, bh, w, h)\n",
    "\n",
    "    def in_bound_ratio(pts):\n",
    "        if not pts: return 0.0\n",
    "        cnt = sum(1 for x,y,v in pts if 0 <= x < w and 0 <= y < h and v > 0)\n",
    "        return cnt / (len(pts) or 1)\n",
    "\n",
    "    return pts_img if in_bound_ratio(pts_img) >= in_bound_ratio(pts_box) else pts_box\n",
    "\n",
    "def draw_keypoints_with_ids(image, pts, color=(0, 255, 0)):\n",
    "    for idx, (x, y, v) in enumerate(pts, start=1):\n",
    "        if v <= 0:\n",
    "            continue\n",
    "        cv2.circle(image, (x, y), 8, color, -1, lineType=cv2.LINE_AA)  # ì  ë” í¼\n",
    "        label = str(idx)\n",
    "        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)  # ê¸€ì”¨ ë” í¼\n",
    "        bg_tl = (x + 10, y - th - 8)\n",
    "        bg_br = (x + 10 + tw + 8, y - 2)\n",
    "        cv2.rectangle(image, bg_tl, bg_br, (0, 0, 0), thickness=-1)\n",
    "        cv2.putText(image, label, (x + 14, y - 6),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "palette = [\n",
    "    (0,255,0), (255,0,0), (0,200,255), (255,140,0), (200,0,200),\n",
    "    (255,255,0), (0,255,255), (255,105,180)\n",
    "]\n",
    "\n",
    "for i, lbl_file in enumerate(sample_labels):\n",
    "    stem = os.path.splitext(lbl_file)[0]\n",
    "    img_path = find_image_path(img_dir, stem)\n",
    "    if img_path is None:\n",
    "        print(f\"[ê²½ê³ ] {stem} ì´ë¯¸ì§€ ì—†ìŒ\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    with open(os.path.join(label_dir, lbl_file), \"r\") as f:\n",
    "        for li, line in enumerate(f):\n",
    "            vals = list(map(float, line.strip().split()))\n",
    "            if len(vals) < 5 + 3:\n",
    "                continue\n",
    "            cls, xc, yc, bw, bh = vals[:5]\n",
    "            kpts = vals[5:]\n",
    "            pts = choose_projection(kpts, xc, yc, bw, bh, w, h)\n",
    "            color = palette[li % len(palette)]\n",
    "            img = draw_keypoints_with_ids(img, pts, color=color)\n",
    "\n",
    "    # â˜… í•œ ì¥ì”© í¬ê²Œ í‘œì‹œ\n",
    "    plt.figure(figsize=(4, 3))  # ë” í¬ê²Œ ë³´ê³  ì‹¶ìœ¼ë©´ (20, 15) ë“±ìœ¼ë¡œ ì¡°ì •\n",
    "    plt.imshow(img)\n",
    "    plt.title(os.path.basename(img_path), fontsize=16)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7856b24a",
   "metadata": {},
   "source": [
    "## MPII"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c0418f",
   "metadata": {},
   "source": [
    "### DATA DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394cbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MP_SAVE_DIR = os.path.join(SAVE_DIR,\"MPII\") # COCO ì´ë¯¸ì§€ ë° ë¼ë²¨ ì €ì¥ ë£¨íŠ¸\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210dd2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # OS ìœ í‹¸\n",
    "import shutil  # íŒŒì¼ ë³µì‚¬\n",
    "import scipy.io as sio  # MAT ë¡œë“œ\n",
    "import numpy as np  # ìˆ˜ì¹˜ ì—°ì‚°\n",
    "from PIL import Image  # ì´ë¯¸ì§€ I/O\n",
    "from tqdm import tqdm  # ì§„í–‰ë°”\n",
    "from collections import defaultdict  # ê¸°ë³¸ ë”•íŠ¸\n",
    "\n",
    "# ============== ì„¤ì • ==============  # ì„¤ì • ì„¹ì…˜\n",
    "SEED = 42  # ëœë¤ ì‹œë“œ\n",
    "MAT_FILE   = '/workspace/nas203/ds_RehabilitationMedicineData/data/body_key_point_Public_Data/MPII/mpii_human_pose_v1_u12_2/mpii_human_pose_v1_u12_1.mat'  # ì£¼ì„ ê²½ë¡œ\n",
    "SRC_IMAGES = '/workspace/nas203/ds_RehabilitationMedicineData/data/body_key_point_Public_Data/MPII/mpii/images'  # ì´ë¯¸ì§€ í´ë”\n",
    "\n",
    "# 5ì (ëª©, ì™¼ì†ëª©, ì˜¤ë¥¸ì†ëª©, ì™¼ë°œëª©, ì˜¤ë¥¸ë°œëª©)ìœ¼ë¡œ ì¶•ì•½: ì‚¬ìš©ì ì§€ì • ì¸ë±ìŠ¤  # ì„ íƒ í‚¤í¬ì¸íŠ¸\n",
    "SELECTED_IDS = [8, 15, 10, 5, 0]  # ì„ íƒ ì¸ë±ìŠ¤\n",
    "\n",
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ êµ¬ì„±  # ì¶œë ¥ ê²½ë¡œ\n",
    "DIRS = {  # ë¶„í• ë³„ ê²½ë¡œ\n",
    "    'train': {  # í•™ìŠµ í´ë”\n",
    "        'images': os.path.join(MP_SAVE_DIR, 'train', 'images'),  # í•™ìŠµ ì´ë¯¸ì§€\n",
    "        'labels5': os.path.join(MP_SAVE_DIR, 'train', 'labels5')  # í•™ìŠµ ë¼ë²¨\n",
    "    },\n",
    "    'val': {  # ê²€ì¦ í´ë”\n",
    "        'images': os.path.join(MP_SAVE_DIR, 'val', 'images'),  # ê²€ì¦ ì´ë¯¸ì§€\n",
    "        'labels5': os.path.join(MP_SAVE_DIR, 'val', 'labels5')  # ê²€ì¦ ë¼ë²¨\n",
    "    }\n",
    "}\n",
    "for split in DIRS:  # ë¶„í•  ìˆœíšŒ\n",
    "    os.makedirs(DIRS[split]['images'], exist_ok=True)  # ì´ë¯¸ì§€ í´ë” ìƒì„±\n",
    "    os.makedirs(DIRS[split]['labels5'], exist_ok=True)  # ë¼ë²¨ í´ë” ìƒì„±\n",
    "\n",
    "# ============== .mat ë¡œë“œ ==============  # MAT ì½ê¸°\n",
    "data     = sio.loadmat(MAT_FILE, squeeze_me=True, struct_as_record=False)  # MAT ë¡œë“œ\n",
    "release  = data['RELEASE']  # ë©”íƒ€ ì¶”ì¶œ\n",
    "annolist = release.annolist  # ì–´ë…¸ ë¦¬ìŠ¤íŠ¸\n",
    "is_train = np.asarray(release.img_train).astype(bool)  # í•™ìŠµ í”Œë˜ê·¸\n",
    "\n",
    "# ============== trainë§Œ ì¶”ì¶œ â†’ ì´ë¯¸ì§€ ê¸°ì¤€ 9:1 ë¶„í•  ==============  # ë¶„í•  ì„¤ì •\n",
    "# annolistëŠ” ì´ë¯¸ì§€ ë‹¨ìœ„ í•­ëª©. ê°™ì€ ì´ë¯¸ì§€ê°€ ì¤‘ë³µë  ê°€ëŠ¥ì„± ë°©ì§€ ìœ„í•´ ì´ë¯¸ì§€ëª…ìœ¼ë¡œ ë¶„í•  ë¦¬ìŠ¤íŠ¸ ìƒì„±  # ì„¤ëª… ì£¼ì„\n",
    "train_indices = [i for i in range(len(annolist)) if is_train[i]]  # í•™ìŠµ ì¸ë±ìŠ¤\n",
    "\n",
    "# ê³ ìœ  ì´ë¯¸ì§€ëª… ê¸°ë°˜ìœ¼ë¡œ ë¶„í•   # ê³ ìœ í™” ì²˜ë¦¬\n",
    "img_to_idx = defaultdict(list)  # ì´ë¯¸ì§€â†’ì¸ë±ìŠ¤\n",
    "for i in train_indices:  # ì¸ë±ìŠ¤ ìˆœíšŒ\n",
    "    img_name = os.path.basename(annolist[i].image.name)  # íŒŒì¼ëª… ì¶”ì¶œ\n",
    "    img_to_idx[img_name].append(i)  # ë§¤í•‘ ì¶”ê°€\n",
    "\n",
    "unique_imgs = list(img_to_idx.keys())  # ê³ ìœ  ëª©ë¡\n",
    "rng = np.random.default_rng(SEED)  # ë‚œìˆ˜ê¸° ì´ˆê¸°í™”\n",
    "rng.shuffle(unique_imgs)  # ì„ê¸°\n",
    "\n",
    "cut = int(len(unique_imgs) * 0.9)  # 9:1 ë¶„í• ì \n",
    "train_imgs = set(unique_imgs[:cut])  # í•™ìŠµ ì§‘í•©\n",
    "val_imgs   = set(unique_imgs[cut:])  # ê²€ì¦ ì§‘í•©\n",
    "\n",
    "def which_split(img_name):  # ë¶„í•  íŒë‹¨\n",
    "    return 'train' if img_name in train_imgs else 'val'  # ë¶„ê¸° ë°˜í™˜\n",
    "\n",
    "# ============== ë³€í™˜ í•¨ìˆ˜ë“¤ ==============  # í•¨ìˆ˜ ì„¹ì…˜\n",
    "def _to_list(x):  # ë¦¬ìŠ¤íŠ¸ ë³€í™˜\n",
    "    \"\"\"numpy scalar/array ë˜ëŠ” ë‹¨ì¼ ê°ì²´ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ í‰íƒ„í™”\"\"\"  # í•¨ìˆ˜ ì„¤ëª…\n",
    "    if x is None:  # ì—†ìŒ ì²˜ë¦¬\n",
    "        return []  # ë¹ˆ ë¦¬ìŠ¤íŠ¸\n",
    "    if isinstance(x, np.ndarray):  # ë°°ì—´ ì—¬ë¶€\n",
    "        return x.tolist()  # ë¦¬ìŠ¤íŠ¸í™”\n",
    "    return [x]  # ë‹¨ì¼ ê°ì‹¸ê¸°\n",
    "\n",
    "def build_labels_for_ann(ann, w, h):  # ë¼ë²¨ ìƒì„±\n",
    "    \"\"\"\n",
    "    ann(í•œ ì´ë¯¸ì§€ í•­ëª©)ì—ì„œ ì‚¬ëŒë³„ ë¼ì¸ë“¤ì„ ìƒì„±.\n",
    "    ë°˜í™˜: ['cls xc yc bw bh kpts...', ...]\n",
    "    \"\"\"  # ë™ì‘ ì„¤ëª…\n",
    "    rects = _to_list(ann.annorect)  # ì‚¬ëŒ ë°•ìŠ¤ë“¤\n",
    "    lines = []  # ê²°ê³¼ ë¼ì¸ë“¤\n",
    "\n",
    "    for r in rects:  # ê° ë°•ìŠ¤ ìˆœíšŒ\n",
    "        if r is None or not hasattr(r, 'annopoints'):  # í¬ì¸íŠ¸ í™•ì¸\n",
    "            continue  # ìŠ¤í‚µ\n",
    "\n",
    "        aps_list = _to_list(r.annopoints)  # í¬ì¸íŠ¸ ì„¸íŠ¸\n",
    "        all_pts = []  # í¬ì¸íŠ¸ ëˆ„ì \n",
    "        for ap in aps_list:  # ì„¸íŠ¸ ìˆœíšŒ\n",
    "            pts = getattr(ap, 'point', None)  # í¬ì¸íŠ¸ ì·¨ë“\n",
    "            all_pts += _to_list(pts)  # ë¦¬ìŠ¤íŠ¸í™” í•©ì¹¨\n",
    "\n",
    "        if not all_pts:  # í¬ì¸íŠ¸ ì—†ìŒ\n",
    "            continue  # ìŠ¤í‚µ\n",
    "\n",
    "        # id ìµœëŒ€ê°’ ê¸°ì¤€ìœ¼ë¡œ í…Œì´ë¸” ë§Œë“¤ê¸°  # í…Œì´ë¸” í¬ê¸°\n",
    "        try:\n",
    "            max_id = max(int(p.id) for p in all_pts)  # ìµœëŒ€ id\n",
    "        except Exception:  # ì‹¤íŒ¨ ì²˜ë¦¬\n",
    "            continue  # ìŠ¤í‚µ\n",
    "\n",
    "        # [x, y, v] í…Œì´ë¸” êµ¬ì„± (vëŠ” score ì‚¬ìš©; ì—†ìœ¼ë©´ 1.0)  # í…Œì´ë¸” ìƒì„±\n",
    "        ktab = [[0.0, 0.0, 0.0] for _ in range(max_id + 1)]  # ì´ˆê¸°í™”\n",
    "        xs, ys = [], []  # ì¢Œí‘œ ëˆ„ì \n",
    "        for p in all_pts:  # í¬ì¸íŠ¸ ìˆœíšŒ\n",
    "            try:\n",
    "                pid = int(p.id)  # í¬ì¸íŠ¸ id\n",
    "                x = float(p.x); y = float(p.y)  # ì¢Œí‘œ ì¶”ì¶œ\n",
    "                v = float(getattr(p, 'score', 1.0))  # ê°€ì‹œì„±\n",
    "            except Exception:  # íŒŒì‹± ì‹¤íŒ¨\n",
    "                continue  # ìŠ¤í‚µ\n",
    "            ktab[pid] = [x, y, v]  # í‘œ ì±„ì›€\n",
    "            xs.append(x); ys.append(y)  # ì¢Œí‘œ ëˆ„ì \n",
    "\n",
    "        if not xs or not ys:  # ì¢Œí‘œ ì—†ìŒ\n",
    "            continue  # ìŠ¤í‚µ\n",
    "\n",
    "        # bbox (ì •ê·œí™”)  # ë°•ìŠ¤ ê³„ì‚°\n",
    "        x_min, x_max = min(xs), max(xs)  # x ë²”ìœ„\n",
    "        y_min, y_max = min(ys), max(ys)  # y ë²”ìœ„\n",
    "        bw = (x_max - x_min) / w  # í­ ì •ê·œí™”\n",
    "        bh = (y_max - y_min) / h  # ë†’ì´ ì •ê·œí™”\n",
    "        if bw <= 0 or bh <= 0:  # ë¹„ì •ìƒ í¬ê¸°\n",
    "            continue  # ìŠ¤í‚µ\n",
    "\n",
    "        xc = ((x_min + x_max) / 2) / w  # ì¤‘ì‹¬ x\n",
    "        yc = ((y_min + y_max) / 2) / h  # ì¤‘ì‹¬ y\n",
    "\n",
    "        # 5ì ë§Œ ì •ê·œí™”í•˜ì—¬ ì¶”ì¶œ  # ì„ íƒì  ì²˜ë¦¬\n",
    "        flat = []  # í‚¤ì  ë²„í¼\n",
    "        for idx in SELECTED_IDS:  # ì„ íƒ ìˆœíšŒ\n",
    "            if 0 <= idx < len(ktab):  # ë²”ìœ„ í™•ì¸\n",
    "                x, y, v = ktab[idx]  # ê°’ ì·¨ë“\n",
    "            else:\n",
    "                x, y, v = 0.0, 0.0, 0.0  # ê¸°ë³¸ê°’\n",
    "            flat += [x / w, y / h, v]  # ì •ê·œí™” ì¶”ê°€\n",
    "\n",
    "        vals = [0, xc, yc, bw, bh] + flat  # í•œ ì¤„ êµ¬ì„±\n",
    "        lines.append(' '.join(f\"{v:.6f}\" for v in vals))  # ë¬¸ìì—´í™”\n",
    "\n",
    "    return lines  # ë¼ë²¨ ë°˜í™˜\n",
    "\n",
    "# ============== ë³¸ë³€í™˜: ì´ë¯¸ì§€ ë³µì‚¬ + labels5 ì‘ì„± ==============  # ë³¸ ì²˜ë¦¬\n",
    "stats = {  # í†µê³„ ë”•íŠ¸\n",
    "    'train': {'files': 0, 'lines': 0, 'copied': 0, 'no_src': 0, 'no_pts': 0},  # í•™ìŠµ í†µê³„\n",
    "    'val':   {'files': 0, 'lines': 0, 'copied': 0, 'no_src': 0, 'no_pts': 0},  # ê²€ì¦ í†µê³„\n",
    "}\n",
    "\n",
    "for i in tqdm(train_indices, desc=\"MPII train â†’ (train/val 9:1) + labels5\", unit=\"img\", dynamic_ncols=True):  # ì¸ë±ìŠ¤ ë£¨í”„\n",
    "    ann = annolist[i]  # ì£¼ì„ í•­ëª©\n",
    "    img_name = os.path.basename(ann.image.name)  # íŒŒì¼ëª…\n",
    "    split = which_split(img_name)  # ë¶„í•  ê²°ì •\n",
    "\n",
    "    src_img = os.path.join(SRC_IMAGES, img_name)  # ì›ë³¸ ê²½ë¡œ\n",
    "    if not os.path.isfile(src_img):  # ì¡´ì¬ í™•ì¸\n",
    "        stats[split]['no_src'] += 1  # ì›ë³¸ ì—†ìŒ ì¹´ìš´íŠ¸\n",
    "        continue  # ìŠ¤í‚µ\n",
    "\n",
    "    # ì´ë¯¸ì§€ í¬ê¸°  # í¬ê¸° ì½ê¸°\n",
    "    try:\n",
    "        with Image.open(src_img) as im:  # ì´ë¯¸ì§€ ì—´ê¸°\n",
    "            w, h = im.size  # í­ ë†’ì´\n",
    "    except Exception:  # ì‹¤íŒ¨ ì‹œ\n",
    "        stats[split]['no_src'] += 1  # ì›ë³¸ ì˜¤ë¥˜ ì¹´ìš´íŠ¸\n",
    "        continue  # ìŠ¤í‚µ\n",
    "\n",
    "    # ë¼ë²¨ ìƒì„±  # í‚¤ì  ìƒì„±\n",
    "    lines = build_labels_for_ann(ann, w, h)  # ë¼ë²¨ ë¹Œë“œ\n",
    "    if not lines:  # ë¹„ì–´ìˆìŒ\n",
    "        stats[split]['no_pts'] += 1  # í¬ì¸íŠ¸ ì—†ìŒ\n",
    "        continue  # ìŠ¤í‚µ\n",
    "\n",
    "    # ì´ë¯¸ì§€ ë³µì‚¬(í•œ ë²ˆë§Œ)  # ì´ë¯¸ì§€ ë³µì‚¬\n",
    "    dst_img = os.path.join(DIRS[split]['images'], img_name)  # ëŒ€ìƒ ê²½ë¡œ\n",
    "    if not os.path.isfile(dst_img):  # ë¯¸ì¡´ì¬ì‹œ\n",
    "        os.makedirs(os.path.dirname(dst_img), exist_ok=True)  # í´ë” ìƒì„±\n",
    "        try:\n",
    "            shutil.copy2(src_img, dst_img)  # ì´ë¯¸ì§€ ë³µì‚¬\n",
    "            stats[split]['copied'] += 1  # ë³µì‚¬ ì¹´ìš´íŠ¸\n",
    "        except Exception:\n",
    "            # ë³µì‚¬ ì‹¤íŒ¨í•´ë„ ë¼ë²¨ì€ ì“¸ ìˆ˜ ìˆê²Œ ì§„í–‰  # ì‹¤íŒ¨ í—ˆìš©\n",
    "            pass  # ê³„ì† ì§„í–‰\n",
    "\n",
    "    # ë¼ë²¨ ì €ì¥ (ì‚¬ëŒ ìˆ˜ë§Œí¼ ë¼ì¸)  # ë¼ë²¨ ì €ì¥\n",
    "    dst_lbl = os.path.join(DIRS[split]['labels5'], os.path.splitext(img_name)[0] + '.txt')  # ë¼ë²¨ ê²½ë¡œ\n",
    "    with open(dst_lbl, 'w') as f:  # íŒŒì¼ ì—´ê¸°\n",
    "        f.write('\\n'.join(lines))  # ë‚´ìš© ê¸°ë¡\n",
    "\n",
    "    stats[split]['files'] += 1  # íŒŒì¼ ìˆ˜ ì¦ê°€\n",
    "    stats[split]['lines'] += len(lines)  # ë¼ì¸ ìˆ˜ ì¦ê°€\n",
    "\n",
    "# ============== ìš”ì•½ ì¶œë ¥ ==============  # ê²°ê³¼ ìš”ì•½\n",
    "print(\"\\nâœ… ì™„ë£Œ: MPII train â†’ (train/val 9:1) ë¶„í•  + YOLO labels5 ìƒì„±\")  # ì™„ë£Œ ì¶œë ¥\n",
    "for split in ('train', 'val'):  # ë¶„í•  ìˆœíšŒ\n",
    "    s = stats[split]  # í†µê³„ ì°¸ì¡°\n",
    "    print(f\"[{split}]\")  # ë¶„í•  ì¶œë ¥\n",
    "    print(f\"  â”œâ”€ ë¼ë²¨ íŒŒì¼ ìˆ˜      : {s['files']}\")  # ë¼ë²¨ ìˆ˜\n",
    "    print(f\"  â”œâ”€ ì´ ë¼ì¸(ì‚¬ëŒ ìˆ˜)   : {s['lines']}\")  # ì´ ë¼ì¸\n",
    "    print(f\"  â”œâ”€ ë³µì‚¬ëœ ì´ë¯¸ì§€ ìˆ˜   : {s['copied']}\")  # ë³µì‚¬ ìˆ˜\n",
    "    print(f\"  â”œâ”€ ìŠ¤í‚µ(ì›ë³¸ ì´ë¯¸ì§€X) : {s['no_src']}\")  # ì›ë³¸ ì—†ìŒ\n",
    "    print(f\"  â””â”€ ìŠ¤í‚µ(í¬ì¸íŠ¸ ì—†ìŒ)  : {s['no_pts']}\")  # í¬ì¸íŠ¸ ì—†ìŒ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c17af1-eef5-4c69-94c5-1238ab03a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- 1) íŠ¹ì • êµ¬ì¡°(COCO) ì¹´ìš´íŠ¸ ----\n",
    "SAVE_BASE = \"./data/Public_data/MPII\"\n",
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    img_dir = os.path.join(SAVE_BASE, split, \"images\")\n",
    "    lbl_dir = os.path.join(SAVE_BASE, split, \"labels5\")\n",
    "\n",
    "    img_count = sum(1 for f in os.listdir(img_dir)\n",
    "                    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")))\n",
    "    lbl_count = sum(1 for f in os.listdir(lbl_dir) if f.lower().endswith(\".txt\"))\n",
    "\n",
    "    # ì´ë¯¸ì§€-ë¼ë²¨ ë§¤ì¹­ ìƒíƒœë„ í•¨ê»˜ ì²´í¬\n",
    "    img_stems = {os.path.splitext(f)[0] for f in os.listdir(img_dir)\n",
    "                 if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))}\n",
    "    lbl_stems = {os.path.splitext(f)[0] for f in os.listdir(lbl_dir)\n",
    "                 if f.lower().endswith(\".txt\")}\n",
    "    missing_lbl = img_stems - lbl_stems\n",
    "    missing_img = lbl_stems - img_stems\n",
    "\n",
    "    print(f\"[{split}] images: {img_count:,} | labels: {lbl_count:,}\")\n",
    "    print(f\"    â”œâ”€ ë¼ë²¨ ì—†ëŠ” ì´ë¯¸ì§€: {len(missing_lbl):,}\")\n",
    "    print(f\"    â””â”€ ì´ë¯¸ì§€ ì—†ëŠ” ë¼ë²¨: {len(missing_img):,}\")\n",
    "\n",
    "# ---- 2) ë²”ìš©: ì„ì˜ í´ë”ì˜ íŒŒì¼ ê°œìˆ˜(í™•ì¥ì/ì¬ê·€ ì˜µì…˜) ----\n",
    "def count_files(dirpath, exts=None, recursive=True):\n",
    "    \"\"\"\n",
    "    dirpath: í´ë” ê²½ë¡œ\n",
    "    exts: ('jpg','png','txt') ì²˜ëŸ¼ í™•ì¥ì íŠœí”Œ/ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì „ì²´)\n",
    "    recursive: í•˜ìœ„ í´ë”ê¹Œì§€ í¬í•¨ ì—¬ë¶€\n",
    "    \"\"\"\n",
    "    dirpath = Path(dirpath)\n",
    "    if exts:\n",
    "        exts = tuple(x.lower().lstrip(\".\") for x in exts)\n",
    "\n",
    "    n = 0\n",
    "    it = dirpath.rglob(\"*\") if recursive else dirpath.iterdir()\n",
    "    for p in it:\n",
    "        if p.is_file():\n",
    "            if not exts:\n",
    "                n += 1\n",
    "            else:\n",
    "                if p.suffix.lower().lstrip(\".\") in exts:\n",
    "                    n += 1\n",
    "    return n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801457a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 180  # ì„ ëª…ë„ ì—…\n",
    "\n",
    "\n",
    "split = \"val\"\n",
    "img_dir = os.path.join(MP_SAVE_DIR, split, \"images\")\n",
    "label_dir = os.path.join(MP_SAVE_DIR, split, \"labels5\")\n",
    "\n",
    "all_labels = [f for f in os.listdir(label_dir) if f.endswith(\".txt\")]\n",
    "sample_labels = random.sample(all_labels, min(5, len(all_labels)))\n",
    "\n",
    "def find_image_path(root, stem):\n",
    "    for ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        p = os.path.join(root, stem + ext)\n",
    "        if os.path.isfile(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def kpts_to_pixels_image_norm(kpts, w, h):\n",
    "    pts = []\n",
    "    for i in range(0, len(kpts), 3):\n",
    "        x, y, v = kpts[i:i+3]\n",
    "        pts.append((int(x * w), int(y * h), v))\n",
    "    return pts\n",
    "\n",
    "def kpts_to_pixels_box_norm(kpts, xc, yc, bw, bh, w, h):\n",
    "    x0 = (xc - bw / 2.0) * w\n",
    "    y0 = (yc - bh / 2.0) * h\n",
    "    bw_px = bw * w\n",
    "    bh_px = bh * h\n",
    "    pts = []\n",
    "    for i in range(0, len(kpts), 3):\n",
    "        xr, yr, v = kpts[i:i+3]\n",
    "        x = int(x0 + xr * bw_px)\n",
    "        y = int(y0 + yr * bh_px)\n",
    "        pts.append((x, y, v))\n",
    "    return pts\n",
    "\n",
    "def choose_projection(kpts, xc, yc, bw, bh, w, h):\n",
    "    pts_img = kpts_to_pixels_image_norm(kpts, w, h)\n",
    "    pts_box = kpts_to_pixels_box_norm(kpts, xc, yc, bw, bh, w, h)\n",
    "\n",
    "    def in_bound_ratio(pts):\n",
    "        if not pts: return 0.0\n",
    "        cnt = sum(1 for x,y,v in pts if 0 <= x < w and 0 <= y < h and v > 0)\n",
    "        return cnt / (len(pts) or 1)\n",
    "\n",
    "    return pts_img if in_bound_ratio(pts_img) >= in_bound_ratio(pts_box) else pts_box\n",
    "\n",
    "def draw_keypoints_with_ids(image, pts, color=(0, 255, 0)):\n",
    "    for idx, (x, y, v) in enumerate(pts, start=1):\n",
    "        if v <= 0:\n",
    "            continue\n",
    "        cv2.circle(image, (x, y), 8, color, -1, lineType=cv2.LINE_AA)  # ì  ë” í¼\n",
    "        label = str(idx)\n",
    "        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)  # ê¸€ì”¨ ë” í¼\n",
    "        bg_tl = (x + 10, y - th - 8)\n",
    "        bg_br = (x + 10 + tw + 8, y - 2)\n",
    "        cv2.rectangle(image, bg_tl, bg_br, (0, 0, 0), thickness=-1)\n",
    "        cv2.putText(image, label, (x + 14, y - 6),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "palette = [\n",
    "    (0,255,0), (255,0,0), (0,200,255), (255,140,0), (200,0,200),\n",
    "    (255,255,0), (0,255,255), (255,105,180)\n",
    "]\n",
    "\n",
    "for i, lbl_file in enumerate(sample_labels):\n",
    "    stem = os.path.splitext(lbl_file)[0]\n",
    "    img_path = find_image_path(img_dir, stem)\n",
    "    if img_path is None:\n",
    "        print(f\"[ê²½ê³ ] {stem} ì´ë¯¸ì§€ ì—†ìŒ\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    with open(os.path.join(label_dir, lbl_file), \"r\") as f:\n",
    "        for li, line in enumerate(f):\n",
    "            vals = list(map(float, line.strip().split()))\n",
    "            if len(vals) < 5 + 3:\n",
    "                continue\n",
    "            cls, xc, yc, bw, bh = vals[:5]\n",
    "            kpts = vals[5:]\n",
    "            pts = choose_projection(kpts, xc, yc, bw, bh, w, h)\n",
    "            color = palette[li % len(palette)]\n",
    "            img = draw_keypoints_with_ids(img, pts, color=color)\n",
    "\n",
    "    # â˜… í•œ ì¥ì”© í¬ê²Œ í‘œì‹œ\n",
    "    plt.figure(figsize=(4, 3))  # ë” í¬ê²Œ ë³´ê³  ì‹¶ìœ¼ë©´ (20, 15) ë“±ìœ¼ë¡œ ì¡°ì •\n",
    "    plt.imshow(img)\n",
    "    plt.title(os.path.basename(img_path), fontsize=16)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f908427c",
   "metadata": {},
   "source": [
    "## AMC DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef572b-718b-4a3b-b9c4-52611b8e52ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter ì…€ì—ì„œ ì‹¤í–‰\n",
    "!apt-get update -y\n",
    "!apt-get install -y fonts-nanum fonts-noto-cjk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac241556-4ae2-4eef-b431-db6752418907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random, cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==== ê²½ë¡œ ====\n",
    "SRC_IMG_DIR   = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/data/yolo_data/images\")\n",
    "SRC_LABEL_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/data/yolo_data/labels\")\n",
    "\n",
    "# ==== ìœ í‹¸ ====\n",
    "def find_image_path(stem, exts=(\".jpg\",\".jpeg\",\".png\",\".bmp\")):\n",
    "    for e in exts:\n",
    "        p = SRC_IMG_DIR / f\"{stem}{e}\"\n",
    "        if p.is_file():\n",
    "            return str(p)\n",
    "    return None\n",
    "\n",
    "def draw_yolo_pose(img, line):\n",
    "    parts = list(map(float, line.strip().split()))\n",
    "    if len(parts) < 5: \n",
    "        return img\n",
    "    cls = int(parts[0])\n",
    "    xc, yc, bw, bh = parts[1:5]\n",
    "    kpts = parts[5:]\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    x1 = int((xc - bw/2) * w)\n",
    "    y1 = int((yc - bh/2) * h)\n",
    "    x2 = int((xc + bw/2) * w)\n",
    "    y2 = int((yc + bh/2) * h)\n",
    "    cv2.rectangle(img, (x1,y1), (x2,y2), (255,0,0), 2)\n",
    "    cv2.putText(img, f\"cls:{cls}\", (x1, max(0,y1-5)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # keypoints (x,y,v) ë°˜ë³µ\n",
    "    for i in range(0, len(kpts), 3):\n",
    "        x, y, v = kpts[i:i+3]\n",
    "        if v > 0:\n",
    "            px, py = int(x * w), int(y * h)\n",
    "            cv2.circle(img, (px, py), 4, (0,255,0), -1, lineType=cv2.LINE_AA)\n",
    "            cv2.putText(img, str(i//3+1), (px+5, py-5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255,255,255), 1, cv2.LINE_AA)\n",
    "    return img\n",
    "\n",
    "# ==== ëœë¤ Nê°œ ì‹œê°í™” ====\n",
    "N = 6\n",
    "label_files = sorted(SRC_LABEL_DIR.glob(\"*.txt\"))\n",
    "samples = random.sample(label_files, min(N, len(label_files)))\n",
    "\n",
    "cols = min(3, len(samples))\n",
    "rows = (len(samples) + cols - 1) // cols\n",
    "plt.figure(figsize=(5*cols, 5*rows))\n",
    "\n",
    "for idx, lbl in enumerate(samples, 1):\n",
    "    stem = lbl.stem\n",
    "    img_path = find_image_path(stem)\n",
    "    if img_path is None:\n",
    "        continue\n",
    "    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    with open(lbl, \"r\") as f:\n",
    "        for line in f:\n",
    "            img = draw_yolo_pose(img, line)\n",
    "\n",
    "    plt.subplot(rows, cols, idx)\n",
    "    plt.imshow(img); plt.axis(\"off\"); plt.title(stem)\n",
    "\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009e858-fa65-4a13-aeb6-f0c7851ba433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# ================================\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "# ================================\n",
    "ROOT = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/data/yolo_data\")\n",
    "SRC_LABEL_DIR = ROOT / \"labels\"\n",
    "SRC_IMAGE_DIR = ROOT / \"images\"  # ì´ë¯¸ì§€ ê²½ë¡œ (í•„ìš” ì‹œ ìˆ˜ì •)\n",
    "\n",
    "DST_ROOT = Path(\"./data/Patient_data\")\n",
    "TRAIN_LABEL_DIR = DST_ROOT / \"train\" / \"labels5\"\n",
    "VAL_LABEL_DIR = DST_ROOT / \"val\" / \"labels5\"\n",
    "TRAIN_IMAGE_DIR = DST_ROOT / \"train\" / \"images\"\n",
    "VAL_IMAGE_DIR = DST_ROOT / \"val\" / \"images\"\n",
    "\n",
    "for d in [TRAIN_LABEL_DIR, VAL_LABEL_DIR, TRAIN_IMAGE_DIR, VAL_IMAGE_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ================================\n",
    "# COCO 17 keypoints â†’ ì„ íƒ ê·œì¹™\n",
    "# ================================\n",
    "ID_LSH, ID_RSH = 5, 6\n",
    "ID_LW, ID_RW   = 9, 10\n",
    "ID_LA, ID_RA   = 15, 16\n",
    "\n",
    "def build_line(cls, bbox, kps, h, w):\n",
    "    \"\"\" YOLO txt í•œ ì¤„ ë³€í™˜ \"\"\"\n",
    "    nx  = (kps[ID_LSH,0] + kps[ID_RSH,0]) / 2 / w\n",
    "    ny  = (kps[ID_LSH,1] + kps[ID_RSH,1]) / 2 / h\n",
    "    nv  = int(min(kps[ID_LSH,2], kps[ID_RSH,2]))\n",
    "\n",
    "    pts = [\n",
    "        (nx, ny, nv),\n",
    "        (kps[ID_LW,0]/w, kps[ID_LW,1]/h, int(kps[ID_LW,2])),\n",
    "        (kps[ID_RW,0]/w, kps[ID_RW,1]/h, int(kps[ID_RW,2])),\n",
    "        (kps[ID_LA,0]/w, kps[ID_LA,1]/h, int(kps[ID_LA,2])),\n",
    "        (kps[ID_RA,0]/w, kps[ID_RA,1]/h, int(kps[ID_RA,2])),\n",
    "    ]\n",
    "\n",
    "    flat = []\n",
    "    for x, y, v in pts:\n",
    "        flat += [f\"{x:.6f}\", f\"{y:.6f}\", str(v)]\n",
    "\n",
    "    return \" \".join([cls] + bbox + flat)\n",
    "\n",
    "# ================================\n",
    "# ë¼ë²¨ ë³€í™˜ (labels â†’ labels5)\n",
    "# ================================\n",
    "print(\"ğŸ”„ ë¼ë²¨ ë³€í™˜ ì¤‘...\")\n",
    "converted_labels = []\n",
    "txt_files = sorted(SRC_LABEL_DIR.glob(\"*.txt\"))\n",
    "\n",
    "for txt_path in tqdm(txt_files, desc=\"ë¼ë²¨ íŒŒì¼ ë³€í™˜\", unit=\"file\"):\n",
    "    out_lines = []\n",
    "    with open(txt_path) as f:\n",
    "        for ln in f:\n",
    "            parts = ln.strip().split()\n",
    "            if len(parts) < 5:\n",
    "                continue\n",
    "            cls, bbox, kplist = parts[0], parts[1:5], parts[5:]\n",
    "            kps = np.array(kplist, float).reshape(-1,3)\n",
    "            out_lines.append(build_line(cls, bbox, kps, h=1, w=1))\n",
    "\n",
    "    if out_lines:\n",
    "        converted_labels.append(txt_path.name)\n",
    "\n",
    "print(f\"âœ… {len(converted_labels)}ê°œ ë¼ë²¨ ë³€í™˜ ì™„ë£Œ\")\n",
    "\n",
    "# ================================\n",
    "# í™˜ì ë‹¨ìœ„ split (9:1)\n",
    "# ================================\n",
    "print(\"ğŸ”„ Train/Val split ì¤‘...\")\n",
    "\n",
    "# í™˜ì ë‹¨ìœ„ ê·¸ë£¹í•‘\n",
    "patient_groups = defaultdict(list)\n",
    "for fname in converted_labels:\n",
    "    prefix = fname.split(\"_\")[0]   # ì–¸ë”ë°” ì• ë¶€ë¶„ì„ í™˜ì IDë¡œ ì‚¬ìš©\n",
    "    patient_groups[prefix].append(fname)\n",
    "\n",
    "patients = list(patient_groups.keys())\n",
    "random.seed(42)\n",
    "random.shuffle(patients)\n",
    "\n",
    "val_ratio = 0.1\n",
    "split_idx = int(len(patients) * (1 - val_ratio))\n",
    "train_patients = patients[:split_idx]\n",
    "val_patients = patients[split_idx:]\n",
    "\n",
    "print(f\"ì´ í™˜ì ìˆ˜: {len(patients)} â†’ Train: {len(train_patients)}, Val: {len(val_patients)}\")\n",
    "\n",
    "# ================================\n",
    "# íŒŒì¼ ë³µì‚¬ (ë¼ë²¨+ì´ë¯¸ì§€)\n",
    "# ================================\n",
    "def copy_files(patients, label_dst, image_dst):\n",
    "    for p in tqdm(patients, desc=f\"{label_dst.parent.name} í™˜ì ì²˜ë¦¬\", unit=\"patient\"):\n",
    "        for fname in patient_groups[p]:\n",
    "            # ë¼ë²¨ íŒŒì¼ ì½ì–´ì„œ ë³€í™˜ ì €ì¥\n",
    "            src_label = SRC_LABEL_DIR / fname\n",
    "            dst_label = label_dst / fname\n",
    "            out_lines = []\n",
    "            with open(src_label) as f:\n",
    "                for ln in f:\n",
    "                    parts = ln.strip().split()\n",
    "                    if len(parts) < 5:\n",
    "                        continue\n",
    "                    cls, bbox, kplist = parts[0], parts[1:5], parts[5:]\n",
    "                    kps = np.array(kplist, float).reshape(-1,3)\n",
    "                    out_lines.append(build_line(cls, bbox, kps, h=1, w=1))\n",
    "            if out_lines:\n",
    "                dst_label.write_text(\"\\n\".join(out_lines))\n",
    "\n",
    "            # ì´ë¯¸ì§€ ë³µì‚¬\n",
    "            stem = Path(fname).stem\n",
    "            for ext in [\".jpg\", \".png\", \".jpeg\"]:\n",
    "                src_img = SRC_IMAGE_DIR / f\"{stem}{ext}\"\n",
    "                if src_img.exists():\n",
    "                    shutil.copy(src_img, image_dst / src_img.name)\n",
    "                    break\n",
    "\n",
    "copy_files(train_patients, TRAIN_LABEL_DIR, TRAIN_IMAGE_DIR)\n",
    "copy_files(val_patients, VAL_LABEL_DIR, VAL_IMAGE_DIR)\n",
    "\n",
    "print(\"âœ… ë°ì´í„° ë¶„í•  ë° ì €ì¥ ì™„ë£Œ\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd3b84f-7cc9-4f07-8ff0-8eeb66789ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ---- 1) íŠ¹ì • êµ¬ì¡°(COCO) ì¹´ìš´íŠ¸ ----\n",
    "SAVE_BASE = \"./data/Patient_data\"\n",
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    img_dir = os.path.join(SAVE_BASE, split, \"images\")\n",
    "    lbl_dir = os.path.join(SAVE_BASE, split, \"labels5\")\n",
    "\n",
    "    img_count = sum(1 for f in os.listdir(img_dir)\n",
    "                    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\")))\n",
    "    lbl_count = sum(1 for f in os.listdir(lbl_dir) if f.lower().endswith(\".txt\"))\n",
    "\n",
    "    # ì´ë¯¸ì§€-ë¼ë²¨ ë§¤ì¹­ ìƒíƒœë„ í•¨ê»˜ ì²´í¬\n",
    "    img_stems = {os.path.splitext(f)[0] for f in os.listdir(img_dir)\n",
    "                 if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))}\n",
    "    lbl_stems = {os.path.splitext(f)[0] for f in os.listdir(lbl_dir)\n",
    "                 if f.lower().endswith(\".txt\")}\n",
    "    missing_lbl = img_stems - lbl_stems\n",
    "    missing_img = lbl_stems - img_stems\n",
    "\n",
    "    print(f\"[{split}] images: {img_count:,} | labels: {lbl_count:,}\")\n",
    "    print(f\"    â”œâ”€ ë¼ë²¨ ì—†ëŠ” ì´ë¯¸ì§€: {len(missing_lbl):,}\")\n",
    "    print(f\"    â””â”€ ì´ë¯¸ì§€ ì—†ëŠ” ë¼ë²¨: {len(missing_img):,}\")\n",
    "\n",
    "# ---- 2) ë²”ìš©: ì„ì˜ í´ë”ì˜ íŒŒì¼ ê°œìˆ˜(í™•ì¥ì/ì¬ê·€ ì˜µì…˜) ----\n",
    "def count_files(dirpath, exts=None, recursive=True):\n",
    "    \"\"\"\n",
    "    dirpath: í´ë” ê²½ë¡œ\n",
    "    exts: ('jpg','png','txt') ì²˜ëŸ¼ í™•ì¥ì íŠœí”Œ/ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì „ì²´)\n",
    "    recursive: í•˜ìœ„ í´ë”ê¹Œì§€ í¬í•¨ ì—¬ë¶€\n",
    "    \"\"\"\n",
    "    dirpath = Path(dirpath)\n",
    "    if exts:\n",
    "        exts = tuple(x.lower().lstrip(\".\") for x in exts)\n",
    "\n",
    "    n = 0\n",
    "    it = dirpath.rglob(\"*\") if recursive else dirpath.iterdir()\n",
    "    for p in it:\n",
    "        if p.is_file():\n",
    "            if not exts:\n",
    "                n += 1\n",
    "            else:\n",
    "                if p.suffix.lower().lstrip(\".\") in exts:\n",
    "                    n += 1\n",
    "    return n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5009dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 180  # ì„ ëª…ë„ ì—…\n",
    "\n",
    "base_dir  = \"./data/Patient_data\"\n",
    "split = \"val\"\n",
    "img_dir =os.path.join(base_dir, split, \"images\")\n",
    "label_dir = os.path.join(base_dir, split, \"labels5\")\n",
    "\n",
    "all_labels = [f for f in os.listdir(label_dir) if f.endswith(\".txt\")]\n",
    "sample_labels = random.sample(all_labels, min(5, len(all_labels)))\n",
    "\n",
    "def find_image_path(root, stem):\n",
    "    for ext in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        p = os.path.join(root, stem + ext)\n",
    "        if os.path.isfile(p):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def kpts_to_pixels_image_norm(kpts, w, h):\n",
    "    pts = []\n",
    "    for i in range(0, len(kpts), 3):\n",
    "        x, y, v = kpts[i:i+3]\n",
    "        pts.append((int(x * w), int(y * h), v))\n",
    "    return pts\n",
    "\n",
    "def kpts_to_pixels_box_norm(kpts, xc, yc, bw, bh, w, h):\n",
    "    x0 = (xc - bw / 2.0) * w\n",
    "    y0 = (yc - bh / 2.0) * h\n",
    "    bw_px = bw * w\n",
    "    bh_px = bh * h\n",
    "    pts = []\n",
    "    for i in range(0, len(kpts), 3):\n",
    "        xr, yr, v = kpts[i:i+3]\n",
    "        x = int(x0 + xr * bw_px)\n",
    "        y = int(y0 + yr * bh_px)\n",
    "        pts.append((x, y, v))\n",
    "    return pts\n",
    "\n",
    "def choose_projection(kpts, xc, yc, bw, bh, w, h):\n",
    "    pts_img = kpts_to_pixels_image_norm(kpts, w, h)\n",
    "    pts_box = kpts_to_pixels_box_norm(kpts, xc, yc, bw, bh, w, h)\n",
    "\n",
    "    def in_bound_ratio(pts):\n",
    "        if not pts: return 0.0\n",
    "        cnt = sum(1 for x,y,v in pts if 0 <= x < w and 0 <= y < h and v > 0)\n",
    "        return cnt / (len(pts) or 1)\n",
    "\n",
    "    return pts_img if in_bound_ratio(pts_img) >= in_bound_ratio(pts_box) else pts_box\n",
    "\n",
    "def draw_keypoints_with_ids(image, pts, color=(0, 255, 0)):\n",
    "    for idx, (x, y, v) in enumerate(pts, start=1):\n",
    "        if v <= 0:\n",
    "            continue\n",
    "        cv2.circle(image, (x, y), 8, color, -1, lineType=cv2.LINE_AA)  # ì  ë” í¼\n",
    "        label = str(idx)\n",
    "        (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.9, 2)  # ê¸€ì”¨ ë” í¼\n",
    "        bg_tl = (x + 10, y - th - 8)\n",
    "        bg_br = (x + 10 + tw + 8, y - 2)\n",
    "        cv2.rectangle(image, bg_tl, bg_br, (0, 0, 0), thickness=-1)\n",
    "        cv2.putText(image, label, (x + 14, y - 6),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    return image\n",
    "\n",
    "palette = [\n",
    "    (0,255,0), (255,0,0), (0,200,255), (255,140,0), (200,0,200),\n",
    "    (255,255,0), (0,255,255), (255,105,180)\n",
    "]\n",
    "\n",
    "for i, lbl_file in enumerate(sample_labels):\n",
    "    stem = os.path.splitext(lbl_file)[0]\n",
    "    img_path = find_image_path(img_dir, stem)\n",
    "    if img_path is None:\n",
    "        print(f\"[ê²½ê³ ] {stem} ì´ë¯¸ì§€ ì—†ìŒ\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    with open(os.path.join(label_dir, lbl_file), \"r\") as f:\n",
    "        for li, line in enumerate(f):\n",
    "            vals = list(map(float, line.strip().split()))\n",
    "            if len(vals) < 5 + 3:\n",
    "                continue\n",
    "            cls, xc, yc, bw, bh = vals[:5]\n",
    "            kpts = vals[5:]\n",
    "            pts = choose_projection(kpts, xc, yc, bw, bh, w, h)\n",
    "            color = palette[li % len(palette)]\n",
    "            img = draw_keypoints_with_ids(img, pts, color=color)\n",
    "\n",
    "    # â˜… í•œ ì¥ì”© í¬ê²Œ í‘œì‹œ\n",
    "    plt.figure(figsize=(4, 3))  # ë” í¬ê²Œ ë³´ê³  ì‹¶ìœ¼ë©´ (20, 15) ë“±ìœ¼ë¡œ ì¡°ì •\n",
    "    plt.imshow(img)\n",
    "    plt.title(os.path.basename(img_path), fontsize=16)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f18deab-4d5d-4b90-8cd5-eb16b2a6e333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
