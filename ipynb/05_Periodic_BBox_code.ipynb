{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb2c3f64",
   "metadata": {},
   "source": [
    "## 경로 설정\n",
    "생성하는 파일들\n",
    "1. frame 폴더   : MP4의 모든 frame을 저장 (2160p)\n",
    "2. JSON 폴더    : sapiens 모델 실행 결과 저장되는 keypoints 위치 json 파일로 저장\n",
    "3. Vis 폴더     : 원본 Frame image에 json 결과 overlay한 결과\n",
    "4. OUTPUT 폴더  : 최종 MP4 파일 위치 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d8916d-797f-4ad4-ad61-8c1e34a57be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU count: 1\n",
      "mmpose: 1.3.2 | mmdet: 3.2.0 | mmengine: 0.10.7 | mmcv: 2.1.0\n",
      "\n",
      "[PATH CHECK]\n",
      "FRAME_DIR    | DIR  | OK | ../data/Patient_data/new_code/frames/M01_VISIT2_상지_frame\n",
      "JSON_DIR     | DIR  | OK | ../data/Patient_data/new_code/json/M01_VISIT2_상지_json\n",
      "VIS_DIR      | DIR  | OK | ../data/Patient_data/new_code/vis/M01_VISIT2_상지_vis\n",
      "MP4_PATH     | FILE | OK | ../../../../data/김원 보산진 연구/M01_VISIT2_상지.MP4\n",
      "OUTPUT_MP4   | FILE | MISSING | ../data/Patient_data/new_code/output/M01_VISIT2_상지_output.mp4\n",
      "DET_CONFIG   | FILE | OK | ../sapiens/pose/demo/mmdetection_cfg/rtmdet_m_640-8xb32_coco-person_no_nms.py\n",
      "DET_CKPT     | FILE | OK | ../sapiens/pose/checkpoints/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n",
      "POSE_CONFIG  | FILE | OK | ../sapiens/pose/configs/sapiens_pose/coco/sapiens_0.3b-210e_coco-1024x768.py\n",
      "POSE_CKPT    | FILE | OK | ../sapiens/pose/checkpoints/sapiens_0.3b/sapiens_0.3b_coco_best_coco_AP_796.pth\n"
     ]
    }
   ],
   "source": [
    "import os, sys, torch\n",
    "import mmpose, mmdet, mmengine, mmcv\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU count:\", torch.cuda.device_count())\n",
    "print(\"mmpose:\", mmpose.__version__, \"| mmdet:\", mmdet.__version__, \"| mmengine:\", mmengine.__version__, \"| mmcv:\", mmcv.__version__)\n",
    "\n",
    "# ← 여기에 사용할 mp4 이름만 바꾸세요 (확장자/경로 제외, 파일명만)\n",
    "mp4_name = \"M01_VISIT2_상지\"    # 예시\n",
    "\n",
    "paths_tpl = {\n",
    "    \"MP4_PATH\":    \"../../../../data/김원 보산진 연구/{mp4_name}.MP4\",\n",
    "    \"FRAME_DIR\":   \"../data/Patient_data/new_code/frames/{mp4_name}_frame\",\n",
    "    \"JSON_DIR\":    \"../data/Patient_data/new_code/json/{mp4_name}_json\",\n",
    "    \"VIS_DIR\":     \"../data/Patient_data/new_code/vis/{mp4_name}_vis\",\n",
    "    \"OUTPUT_MP4\":  \"../data/Patient_data/new_code/output/{mp4_name}_output.mp4\",\n",
    "    \"DET_CONFIG\":  \"../sapiens/pose/demo/mmdetection_cfg/rtmdet_m_640-8xb32_coco-person_no_nms.py\",\n",
    "    \"DET_CKPT\":    \"../sapiens/pose/checkpoints/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\",\n",
    "    \"POSE_CONFIG\": \"../sapiens/pose/configs/sapiens_pose/coco/sapiens_0.3b-210e_coco-1024x768.py\",\n",
    "    \"POSE_CKPT\":   \"../sapiens/pose/checkpoints/sapiens_0.3b/sapiens_0.3b_coco_best_coco_AP_796.pth\",\n",
    "}\n",
    "\n",
    "# {mp4_name} 치환\n",
    "paths = {k: v.format(mp4_name=mp4_name) for k, v in paths_tpl.items()}\n",
    "\n",
    "# 디렉토리는 생성, 파일은 존재 여부만 확인\n",
    "dir_keys  = [\"FRAME_DIR\", \"JSON_DIR\", \"VIS_DIR\"]\n",
    "file_keys = [\"MP4_PATH\", \"OUTPUT_MP4\", \"DET_CONFIG\", \"DET_CKPT\", \"POSE_CONFIG\", \"POSE_CKPT\"]\n",
    "\n",
    "for k in dir_keys:\n",
    "    Path(paths[k]).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\n[PATH CHECK]\")\n",
    "for k in dir_keys + file_keys:\n",
    "    p = paths[k]\n",
    "    exists = Path(p).exists()\n",
    "    typ = \"DIR \" if k in dir_keys else \"FILE\"\n",
    "    print(f\"{k:12s} | {typ} | {'OK' if exists else 'MISSING'} | {p}\")\n",
    "\n",
    "# 사용 예시:\n",
    "# cap = cv2.VideoCapture(paths[\"MP4_PATH\"])\n",
    "# output_mp4 = paths[\"OUTPUT_MP4\"]\n",
    "# frame_dir  = paths[\"FRAME_DIR\"]\n",
    "# json_dir   = paths[\"JSON_DIR\"]\n",
    "# vis_dir    = paths[\"VIS_DIR\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11e35c8",
   "metadata": {},
   "source": [
    "## Frame 추출\n",
    "설정할 수 있는 것\n",
    "1. 시간             : 초반 몇 초를 뽑을 것인가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "24bbab13-5191-4265-9633-7e40aa92e3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 29.970 | 총 프레임: 35841 | 저장 예정 프레임: 899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting first 20s frames: 100% 899/899 [02:35<00:00,  5.76frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료: 899장 저장 → ../data/test_patient_image/new_code/M04VISIT12_ori_frame\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 입력 비디오와 출력 폴더\n",
    "DATA_DIR = r\"../../../../data/김원 보산진 연구/M04_VISIT2.MP4\"\n",
    "OUTPUT_DIR = r\"../data/test_patient_image/new_code/M04VISIT12_ori_frame\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 비디오 열기\n",
    "cap = cv2.VideoCapture(DATA_DIR)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"비디오를 열 수 없습니다: {DATA_DIR}\")\n",
    "\n",
    "# FPS와 총 프레임 수 읽기\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.get(cv2.CAP_PROP_FRAME_COUNT) > 0 else -1\n",
    "\n",
    "# 저장할 프레임 수 계산 (앞 20초)\n",
    "if fps and fps > 0:\n",
    "    target_frames = int(round(30 * fps))\n",
    "    if frame_count > 0:\n",
    "        target_frames = min(target_frames, frame_count)\n",
    "else:\n",
    "    # FPS를 얻지 못한 경우: 시간 기준으로 루프에서 20초를 넘지 않게 처리\n",
    "    target_frames = None\n",
    "\n",
    "print(f\"FPS: {fps:.3f} | 총 프레임: {frame_count} | 저장 예정 프레임: {target_frames if target_frames is not None else '시간 기준'}\")\n",
    "\n",
    "saved = 0\n",
    "idx = 0\n",
    "\n",
    "# 진행률 바 설정\n",
    "pbar_total = target_frames if target_frames is not None else 100  # 대략 값\n",
    "pbar = tqdm(total=pbar_total, desc=\"Extracting first 20s frames\", unit=\"frame\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 현재 시간(ms) 확인 (FPS가 불확실할 때 사용)\n",
    "    pos_msec = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "\n",
    "    # 20초 초과하면 중단\n",
    "    if (target_frames is None and pos_msec >= 20000) or (target_frames is not None and idx >= target_frames):\n",
    "        break\n",
    "\n",
    "    # 저장\n",
    "    out_path = os.path.join(OUTPUT_DIR, f\"frame_{idx:06d}.jpg\")\n",
    "    ok = cv2.imwrite(out_path, frame, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "    if ok:\n",
    "        saved += 1\n",
    "        if target_frames is not None:\n",
    "            pbar.update(1)\n",
    "        else:\n",
    "            # 시간 기준일 때는 대략 진행률 표시\n",
    "            pbar.update(1 if saved < pbar_total else 0)\n",
    "    idx += 1\n",
    "\n",
    "pbar.close()\n",
    "cap.release()\n",
    "print(f\"완료: {saved}장 저장 → {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0399756",
   "metadata": {},
   "source": [
    "## sapiens 모델 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3c6df3b-8060-4fb5-9817-1ac66f73e340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/importlib/__init__.py:169: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  _bootstrap._exec(spec, module)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../sapiens/pose/checkpoints/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n",
      "Loads checkpoint by local backend from path: ../sapiens/pose/checkpoints/sapiens_0.3b/sapiens_0.3b_coco_best_coco_AP_796.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "missing keys in source state_dict: head.deconv_layers.1.weight, head.deconv_layers.1.bias, head.deconv_layers.1.running_mean, head.deconv_layers.1.running_var, head.deconv_layers.4.weight, head.deconv_layers.4.bias, head.deconv_layers.4.running_mean, head.deconv_layers.4.running_var, head.conv_layers.1.weight, head.conv_layers.1.bias, head.conv_layers.1.running_mean, head.conv_layers.1.running_var, head.conv_layers.4.weight, head.conv_layers.4.bias, head.conv_layers.4.running_mean, head.conv_layers.4.running_var\n",
      "\n",
      "모델 초기화 완료 ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmengine/utils/manager.py:113: UserWarning: <class 'mmpose.visualization.local_visualizer.PoseLocalVisualizer'> instance named of visualizer has been created, the method `get_instance` should not accept any other arguments\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "```python\n",
    "import mmpretrain  # VisionTransformer 등록\n",
    "\n",
    "import mmcv\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmpose.apis import init_model as init_pose_estimator, inference_topdown\n",
    "from mmpose.utils import adapt_mmdet_pipeline\n",
    "from mmpose.registry import VISUALIZERS\n",
    "from mmpose.evaluation.functional import nms\n",
    "from mmpose.structures import merge_data_samples, split_instances\n",
    "\n",
    "# 경로\n",
    "DATA_DIR = \"../data/Patient_data/new_code/frames/M03_VISIT6_상지_frame\"  # ← 경로만 변경\n",
    "DET_CONFIG = \"../sapiens/pose/demo/mmdetection_cfg/rtmdet_m_640-8xb32_coco-person_no_nms.py\"\n",
    "DET_CKPT   = \"../sapiens/pose/checkpoints/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\"\n",
    "POSE_CONFIG= \"../sapiens/pose/configs/sapiens_pose/coco/sapiens_0.3b-210e_coco-1024x768.py\"\n",
    "POSE_CKPT  = \"../sapiens/pose/checkpoints/sapiens_0.3b/sapiens_0.3b_coco_best_coco_AP_796.pth\"\n",
    "\n",
    "# detector\n",
    "detector = init_detector(DET_CONFIG, DET_CKPT, device=\"cuda:0\")\n",
    "detector.cfg = adapt_mmdet_pipeline(detector.cfg)\n",
    "\n",
    "# pose estimator  (override_ckpt_meta 제거)\n",
    "pose_estimator = init_pose_estimator(\n",
    "    POSE_CONFIG, POSE_CKPT,\n",
    "    device=\"cuda:0\",\n",
    "    cfg_options=dict(model=dict(test_cfg=dict(output_heatmaps=False)))\n",
    ")\n",
    "\n",
    "# 시각화기\n",
    "visualizer = VISUALIZERS.build(pose_estimator.cfg.visualizer)\n",
    "visualizer.set_dataset_meta(pose_estimator.dataset_meta, skeleton_style=\"mmpose\")\n",
    "\n",
    "print(\"모델 초기화 완료 ✅\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc3639f",
   "metadata": {},
   "source": [
    "## Sapiens 모델 실행\n",
    "이때 Bbox는 5 Frame 마다 진행함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5680e22-5502-48f0-97cf-c68df06a072c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 899장 → 15fps용 450장 선택\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 450/450 [04:26<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료. 성공 450, 실패 0, 출력: ../data/test_patient_image/new_code/M04VISIT12_ori_json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 30→15fps 다운샘플 + 주기적 검출 + 이전 포즈 bbox 재사용 (detector/pose_estimator/visualizer/DATA_DIR는 이전 셀에서 초기화됨) ---\n",
    "import os, re, glob, json, numpy as np, mmcv, cv2                  # 표준/수치/영상/경로 라이브러리 임포트\n",
    "from tqdm import tqdm                                               # 진행률 표시 바\n",
    "from mmdet.apis import inference_detector                           # 사람 검출 API\n",
    "from mmpose.apis import inference_topdown                           # 탑다운 포즈 추정 API\n",
    "from mmpose.evaluation.functional import nms                        # NMS(겹침 박스 제거)\n",
    "from mmpose.structures import merge_data_samples, split_instances   # 포즈 결과 병합/분리 유틸\n",
    "\n",
    "OUTPUT_DIR = r\"../data/test_patient_image/new_code/M04VISIT12_ori_json\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)                               # 출력 폴더가 없으면 생성\n",
    "\n",
    "def natural_key(s: str):                                            # 자연 정렬용 키 함수(파일명 속 숫자를 실제 숫자로 취급)\n",
    "    base = os.path.basename(s)                                      # 파일명만 추출\n",
    "    return [int(t) if t.isdigit() else t.lower()                    # 숫자는 int로, 문자는 소문자로 변환\n",
    "            for t in re.split(r'(\\d+)', base)]                      # 숫자/문자 구분하여 분리\n",
    "\n",
    "all_frames = sorted(                                                # 원본 프레임 파일 경로 목록\n",
    "    [p for p in glob.glob(os.path.join(DATA_DIR, \"*\"))              # DATA_DIR 내 모든 파일 중에서\n",
    "     if p.lower().endswith((\".jpg\", \".png\", \".jpeg\"))],             # 이미지 확장자만 필터링\n",
    "    key=natural_key)                                                # 자연 정렬 적용\n",
    "assert all_frames, f\"이미지 없음: {DATA_DIR}\"                       # 이미지가 하나도 없으면 중단\n",
    "frames = all_frames[::2]                                            # 30fps → 15fps: 2프레임마다 1장 선택\n",
    "print(f\"전체 {len(all_frames)}장 → 15fps용 {len(frames)}장 선택\")     # 다운샘플링 결과 출력\n",
    "\n",
    "def to_py(obj):                                                     # numpy/tensor-like → JSON 직렬화 가능 객체로 변환\n",
    "    import numpy as _np                                             # 지역 임포트(이 함수 내부에서만 사용)\n",
    "    if isinstance(obj, _np.ndarray): return obj.tolist()            # ndarray → list\n",
    "    if isinstance(obj, (_np.floating,)): return float(obj)          # numpy float → float\n",
    "    if isinstance(obj, (_np.integer,)):  return int(obj)            # numpy int → int\n",
    "    if isinstance(obj, dict):  return {k: to_py(v) for k, v in obj.items()}  # dict 재귀 처리\n",
    "    if isinstance(obj, (list, tuple)): return [to_py(v) for v in obj]        # list/tuple 재귀 처리\n",
    "    return obj                                                      # 그 외는 그대로 반환\n",
    "\n",
    "def clip_xyxy(xyxy, w, h):                                          # 박스 좌표를 이미지 경계 내로 클립\n",
    "    x1, y1, x2, y2 = xyxy                                           # 좌상단(x1,y1), 우하단(x2,y2)\n",
    "    return [max(0, x1), max(0, y1), min(w - 1, x2), min(h - 1, y2)] # 경계 밖이면 잘라서 반환\n",
    "\n",
    "def bbox_from_keypoints(kpts, scores, thr=0.3, pad_scale=1.25, img_wh=None):  # 키포인트로부터 박스 추정\n",
    "    valid = scores >= thr                                           # 신뢰도 임계 이상인 키포인트만 사용\n",
    "    if valid.sum() == 0:                                            # 유효 키포인트가 없으면\n",
    "        return None                                                 # 박스 생성 불가\n",
    "    xy = kpts[valid]                                                # 유효 키포인트 좌표만 선택 (K',2)\n",
    "    x1, y1 = xy.min(axis=0)                                         # 최소 x,y\n",
    "    x2, y2 = xy.max(axis=0)                                         # 최대 x,y\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2                           # 중심 좌표\n",
    "    w, h = max(2.0, x2 - x1), max(2.0, y2 - y1)                     # 최소 크기 보장(0 폭/높이 방지)\n",
    "    w2, h2 = w * pad_scale / 2, h * pad_scale / 2                   # 패딩 반영한 반폭/반높이\n",
    "    bx = [cx - w2, cy - h2, cx + w2, cy + h2]                       # 패딩된 박스 좌표\n",
    "    if img_wh is not None:                                          # 이미지 크기가 주어졌다면\n",
    "        bx = clip_xyxy(bx, img_wh[0], img_wh[1])                    # 경계 내로 클립\n",
    "    return bx                                                       # 박스 반환\n",
    "\n",
    "det_every = 5    # 몇 프레임마다 검출할지(15fps 기준 약 0.33초 간격)\n",
    "det_thr   = 0.5  # 검출 score 임계값(단일 대상이면 높일수록 잡박스 감소)\n",
    "nms_thr   = 0.5  # NMS IoU 임계값\n",
    "kpt_thr   = 0.3  # 키포인트 표시/박스 생성 시 사용할 신뢰도 임계값               \n",
    "pad_scale = 1.30 # 키포인트 박스 패딩 배율(살짝 여유 공간 확보)             \n",
    "miss_max  = 2    # 포즈에서 bbox 재구성 실패 허용 횟수(연속)                     \n",
    "\n",
    "prev_bbox = None # 이전 프레임에서 이어받은 박스(없으면 검출 강제)                     \n",
    "miss_cnt  = 0    # 연속 bbox 생성 실패 횟수(임계 초과 시 재검출)                   \n",
    "ok, fail  = 0, 0 # 처리 성공/실패 카운터                        \n",
    "\n",
    "for i, img_path in enumerate(tqdm(frames)):                          # 다운샘플된 프레임을 순서대로 처리\n",
    "    try:                                                             # 예외 처리 블록 시작\n",
    "        img_bgr = cv2.imread(img_path)                               # 이미지 로드(BGR)\n",
    "        if img_bgr is None:                                          # 로드 실패 시\n",
    "            continue                                                 # 해당 프레임 스킵\n",
    "        H, W = img_bgr.shape[:2]                                     # 이미지 높이/너비\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)           # RGB로 변환(mmdet/mmpose 사용)\n",
    "\n",
    "        need_det = (i % det_every == 0) or (prev_bbox is None) or (miss_cnt > miss_max)  # 이번 프레임에서 검출 필요한지 판단\n",
    "        if need_det:                                                 # 검출이 필요한 경우\n",
    "            det = inference_detector(detector, img_rgb)              # 사람 검출 실행\n",
    "            pred = det.pred_instances.cpu().numpy()                  # 결과를 numpy로 변환\n",
    "            if len(pred.bboxes):                                     # 박스가 하나 이상이면\n",
    "                bbs = np.concatenate((pred.bboxes,                   # (x1,y1,x2,y2) + score 결합\n",
    "                                       pred.scores[:, None]), axis=1)\n",
    "                keep = (pred.labels == 0) & (pred.scores > det_thr)  # 사람 클래스(0) + 점수 필터\n",
    "                bbs = bbs[keep]                                      # 필터 적용\n",
    "                if len(bbs) > 0:                                     # 남은 박스가 있으면\n",
    "                    bbs = bbs[nms(bbs, nms_thr), :4]                 # NMS 적용 후 좌표만 취득\n",
    "                if len(bbs) > 0:                                     # NMS 후에도 박스가 있으면\n",
    "                    areas = (bbs[:, 2] - bbs[:, 0]) * (bbs[:, 3] - bbs[:, 1])  # 각 박스 면적 계산\n",
    "                    prev_bbox = bbs[np.argmax(areas)].tolist()       # 가장 큰 박스를 선택(단일 대상 가정)\n",
    "                    miss_cnt = 0                                     # 미스 카운트 리셋\n",
    "                else:                                                # 박스가 사라졌다면\n",
    "                    prev_bbox = None                                 # 추적 박스 초기화\n",
    "            else:                                                    # 검출 결과가 비어 있으면\n",
    "                prev_bbox = None                                     # 추적 박스 초기화\n",
    "\n",
    "        bboxes_np = (np.array([prev_bbox], dtype=np.float32)         # 현재 프레임에서 사용할 bbox 배열\n",
    "                     if prev_bbox is not None                        # 이전 박스가 있으면 1개 박스 사용\n",
    "                     else np.empty((0, 4), dtype=np.float32))        # 없으면 빈 배열(포즈 추정 스킵)\n",
    "\n",
    "        pose_results = inference_topdown(pose_estimator, img_rgb, bboxes_np)  # 포즈 추정 실행\n",
    "        data_sample  = merge_data_samples(pose_results)              # 배치 결과 병합(단일/다중 인스턴스 대응)\n",
    "\n",
    "        inst = data_sample.get('pred_instances', None)               # 예측 인스턴스 딕셔너리 취득\n",
    "        if inst is not None and len(inst.get('keypoints', [])) > 0:  # 포즈가 하나 이상 감지되면\n",
    "            kpts_all    = inst['keypoints']                          # (N,K,2) 모든 사람의 키포인트 좌표\n",
    "            kscores_all = inst['keypoint_scores']                    # (N,K)  모든 사람의 키포인트 신뢰도\n",
    "            idx = int(np.argmax(kscores_all.mean(axis=1)))           # 평균 신뢰도가 가장 높은 사람 선택\n",
    "            kpts, kscores = kpts_all[idx], kscores_all[idx]          # 선택된 사람의 키포인트/점수\n",
    "            nb = bbox_from_keypoints(kpts, kscores,                  # 키포인트로 다음 프레임용 bbox 생성\n",
    "                                     thr=kpt_thr, pad_scale=pad_scale,\n",
    "                                     img_wh=(W, H))\n",
    "            if nb is not None:                                       # 박스 생성에 성공하면\n",
    "                prev_bbox = nb                                       # 추적 박스 업데이트\n",
    "                miss_cnt = 0                                         # 미스 카운트 리셋\n",
    "            else:                                                    # 박스 생성 실패 시\n",
    "                miss_cnt += 1                                        # 미스 카운트 증가\n",
    "        else:                                                        # 포즈가 전혀 없으면\n",
    "            miss_cnt += 1                                            # 미스 카운트 증가\n",
    "\n",
    "\n",
    "        # ===== [이미지 시각화/저장 비활성화] =====\n",
    "        # visualizer.add_datasample(                                   # 시각화기에게 결과 렌더링 요청\n",
    "        #     name=\"result\",                                           # 샘플 이름(임의)\n",
    "        #     image=img_rgb,                                           # 원본 RGB 이미지\n",
    "        #     data_sample=data_sample,                                 # 포즈 예측 결과\n",
    "        #     draw_gt=False,                                           # GT(정답) 미표시\n",
    "        #     draw_bbox=False,                                          # bbox 그리기\n",
    "        #     kpt_thr=kpt_thr,                                         # 키포인트 표시 임계값\n",
    "        #     show=False)                                              # 노트북 창 표시 안 함(파일로만 저장)\n",
    "\n",
    "        # out_img = os.path.join(OUTPUT_DIR, os.path.basename(img_path))  # 출력 이미지 경로\n",
    "        # mmcv.imwrite(mmcv.rgb2bgr(visualizer.get_image()), out_img)     # 렌더 결과(BGR) 저장\n",
    "\n",
    "        # ===== JSON만 저장 =====\n",
    "        if inst is not None:\n",
    "            inst_list = split_instances(inst)\n",
    "            payload = dict(meta_info=pose_estimator.dataset_meta,\n",
    "                           instance_info=inst_list)\n",
    "        \n",
    "            # ✅ out_img 쓰지 말고 직접 파일명으로 경로 생성\n",
    "            base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "            json_path = os.path.join(OUTPUT_DIR, base + \".json\")\n",
    "        \n",
    "            with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(to_py(payload), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "        ok += 1                                                       # 성공 카운트 증가\n",
    "\n",
    "    except Exception as e:                                            # 예외 발생 시\n",
    "        fail += 1                                                     # 실패 카운트 증가\n",
    "        print(\"에러:\", os.path.basename(img_path), \"->\", e)           # 파일명과 에러 메시지 출력\n",
    "\n",
    "print(f\"완료. 성공 {ok}, 실패 {fail}, 출력: {OUTPUT_DIR}\")            # 전체 처리 요약 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f986692",
   "metadata": {},
   "source": [
    "## Overlay image 생성\n",
    "json과 ori_img를 통해 overlay iamge 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b38f0220-1770-4802-83ee-5f648531862b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overlay 30fps: 100% 899/899 [03:49<00:00,  3.93frame/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "완료: 오버레이 이미지 899개 저장, 스킵 0개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 15fps 예측(JSON) → 30fps 업샘플: JSON 저장 없이 '오버레이 이미지'만 저장 ---\n",
    "import os, re, glob, json            # 경로/정렬/파일검색/JSON\n",
    "import cv2                           # OpenCV (이미지 로드/저장, 그리기)\n",
    "import numpy as np                   # 수치 계산\n",
    "from tqdm import tqdm                # 진행률 표시\n",
    "\n",
    "# ===== 경로 =====\n",
    "DATA_DIR     = \"../data/test_patient_image/new_code/M04VISIT12_ori_frame\"          # 원본 30fps 프레임 폴더\n",
    "SRC_JSON_DIR = \"../data/test_patient_image/new_code/M04VISIT12_ori_json\"     # 15fps 결과 JSON 폴더\n",
    "OUT_VIS_DIR  = \"../data/test_patient_image/new_code/M04VISIT12_ori_vis\"  # 30fps 오버레이 저장\n",
    "os.makedirs(OUT_VIS_DIR, exist_ok=True)\n",
    "\n",
    "# ===== 자연 정렬 =====\n",
    "def natural_key(s: str):\n",
    "    base = os.path.basename(s)\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.split(r'(\\d+)', base)]\n",
    "\n",
    "# ===== 30fps 전체 프레임 목록 =====\n",
    "all_frames = sorted(\n",
    "    [p for p in glob.glob(os.path.join(DATA_DIR, \"*\")) if p.lower().endswith((\".jpg\",\".png\",\".jpeg\"))],\n",
    "    key=natural_key\n",
    ")\n",
    "assert all_frames, f\"원본 프레임이 없습니다: {DATA_DIR}\"\n",
    "\n",
    "# ===== 15fps JSON 맵 =====\n",
    "src_json_files = sorted(glob.glob(os.path.join(SRC_JSON_DIR, \"*.json\")), key=natural_key)\n",
    "assert src_json_files, f\"15fps JSON이 없습니다: {SRC_JSON_DIR}\"\n",
    "src_json_map = {os.path.splitext(os.path.basename(p))[0]: p for p in src_json_files}\n",
    "\n",
    "# ===== 시각화 파라미터 (단일 색) =====\n",
    "KPT_THR         = 0.05                # 키포인트 신뢰도 임계값 (필요시 0.2~0.3으로 올려 노이즈 제거)\n",
    "KEYPOINT_COLOR  = (0, 255, 0)         # 점 색 (BGR)\n",
    "SKELETON_COLOR  = (255, 128, 0)       # 선 색 (BGR)\n",
    "RADIUS          = 4                   # 점 반지름\n",
    "THICKNESS       = 2                   # 선 두께\n",
    "ANTI_ALIAS      = cv2.LINE_AA         # 안티앨리어싱\n",
    "\n",
    "# ===== 스켈레톤 링크 얻기 =====\n",
    "def get_links(meta: dict):\n",
    "    if \"skeleton_links\" in meta:\n",
    "        return meta[\"skeleton_links\"]\n",
    "    if \"skeleton\" in meta:\n",
    "        return meta[\"skeleton\"]\n",
    "    return []\n",
    "\n",
    "# ===== 한 인스턴스 그리기 (단일 색, bbox X) =====\n",
    "def draw_instance_uniform(img_bgr, instance: dict, links, kpt_thr=0.05):\n",
    "    kpts = np.array(instance[\"keypoints\"], dtype=np.float32)\n",
    "    ksc  = np.array(instance[\"keypoint_scores\"], dtype=np.float32)\n",
    "    # 키포인트(점)\n",
    "    for xy, sc in zip(kpts, ksc):\n",
    "        if sc < kpt_thr:\n",
    "            continue\n",
    "        x, y = int(xy[0]), int(xy[1])\n",
    "        cv2.circle(img_bgr, (x, y), RADIUS, KEYPOINT_COLOR, -1, lineType=ANTI_ALIAS)\n",
    "    # 스켈레톤(선)\n",
    "    for link in links:\n",
    "        if isinstance(link, dict) and \"link\" in link:\n",
    "            i, j = link[\"link\"]\n",
    "        elif isinstance(link, (list, tuple)) and len(link) == 2:\n",
    "            i, j = link\n",
    "        else:\n",
    "            continue\n",
    "        if i >= len(kpts) or j >= len(kpts):\n",
    "            continue\n",
    "        if ksc[i] < kpt_thr or ksc[j] < kpt_thr:\n",
    "            continue\n",
    "        p1 = (int(kpts[i][0]), int(kpts[i][1]))\n",
    "        p2 = (int(kpts[j][0]), int(kpts[j][1]))\n",
    "        cv2.line(img_bgr, p1, p2, SKELETON_COLOR, THICKNESS, lineType=ANTI_ALIAS)\n",
    "\n",
    "# ===== 메인: 30fps 모든 프레임에 대해 오버레이 이미지 저장 (JSON은 저장하지 않음) =====\n",
    "last_json_data = None\n",
    "written_img, skipped = 0, 0\n",
    "\n",
    "for fpath in tqdm(all_frames, desc=\"Overlay 30fps\", unit=\"frame\"):\n",
    "    base = os.path.splitext(os.path.basename(fpath))[0]           # 예: frame_000123\n",
    "    # 15fps JSON 있으면 로드, 없으면 직전 JSON을 사용(Zero-Order Hold)\n",
    "    src_json_path = src_json_map.get(base, None)\n",
    "    if src_json_path is not None:\n",
    "        with open(src_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            json_data = json.load(f)\n",
    "        last_json_data = json_data\n",
    "    else:\n",
    "        if last_json_data is None:\n",
    "            # (초반부 예외 처리) 앞으로 보이는 첫 JSON 1회용 사용\n",
    "            next_json_path = None\n",
    "            for nb in sorted(src_json_map.keys(), key=natural_key):\n",
    "                if nb > base:\n",
    "                    next_json_path = src_json_map[nb]\n",
    "                    break\n",
    "            if next_json_path is None:\n",
    "                skipped += 1\n",
    "                continue\n",
    "            with open(next_json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                json_data = json.load(f)\n",
    "        else:\n",
    "            json_data = last_json_data\n",
    "\n",
    "    # 원본 프레임 로드\n",
    "    img_bgr = cv2.imread(fpath)\n",
    "    if img_bgr is None:\n",
    "        skipped += 1\n",
    "        continue\n",
    "\n",
    "    # 스켈레톤/키포인트 그리기\n",
    "    meta      = json_data.get(\"meta_info\", {})\n",
    "    instances = json_data.get(\"instance_info\", [])\n",
    "    links     = get_links(meta)\n",
    "    for inst in instances:\n",
    "        draw_instance_uniform(img_bgr, inst, links, kpt_thr=KPT_THR)\n",
    "\n",
    "    # 오버레이 이미지 저장\n",
    "    out_img_path = os.path.join(OUT_VIS_DIR, base + \".jpg\")\n",
    "    if cv2.imwrite(out_img_path, img_bgr):\n",
    "        written_img += 1\n",
    "    else:\n",
    "        skipped += 1\n",
    "\n",
    "print(f\"완료: 오버레이 이미지 {written_img}개 저장, 스킵 {skipped}개\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa1ce3b",
   "metadata": {},
   "source": [
    "## MP4 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69e8e3d4-04aa-4695-bd5f-72d1a63c871a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding 30fps MP4: 100% 899/899 [02:18<00:00,  6.50frame/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30fps 비디오 저장 완료: ../data/test_patient_image/new_code/M04VISIT12_ori_output.mp4\n"
     ]
    }
   ],
   "source": [
    "# --- 업샘플된 30fps 시각화 프레임 → 30fps MP4 (tqdm 진행률, 지정 경로 저장) ---\n",
    "import os, re, glob, cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 업샘플된 30fps 프레임들이 있는 폴더 (그림 이미지들)\n",
    "\n",
    "VIS_DIR  = \"../data/test_patient_image/new_code/M04VISIT12_ori_vis\"  # 30fps 오버레이 저장\n",
    "\n",
    "# MP4 저장 폴더와 파일명\n",
    "SAVE_ROOT = \"../data/test_patient_image/new_code\"\n",
    "os.makedirs(SAVE_ROOT, exist_ok=True)\n",
    "SAVE_MP4  = os.path.join(SAVE_ROOT, \"M04VISIT12_ori_output.mp4\")\n",
    "\n",
    "def natural_key(s: str):\n",
    "    base = os.path.basename(s)\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.split(r'(\\d+)', base)]\n",
    "\n",
    "# 프레임 수집 (자연 정렬)\n",
    "frames = sorted(\n",
    "    [p for p in glob.glob(os.path.join(VIS_DIR, \"*\")) if p.lower().endswith((\".jpg\", \".png\", \".jpeg\"))],\n",
    "    key=natural_key\n",
    ")\n",
    "assert frames, f\"프레임 이미지가 없습니다: {VIS_DIR}\"\n",
    "\n",
    "# 비디오 라이터 초기화\n",
    "first = cv2.imread(frames[0])\n",
    "assert first is not None, f\"첫 프레임 로드 실패: {frames[0]}\"\n",
    "h, w = first.shape[:2]\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # 호환성 좋은 코덱\n",
    "writer = cv2.VideoWriter(SAVE_MP4, fourcc, 30, (w, h))\n",
    "\n",
    "# 인코딩 루프 (tqdm 진행률)\n",
    "for f in tqdm(frames, desc=\"Encoding 30fps MP4\", unit=\"frame\"):\n",
    "    img = cv2.imread(f)\n",
    "    if img is None:\n",
    "        print(f\"[경고] 프레임 로드 실패: {f}\")\n",
    "        continue\n",
    "    if img.shape[:2] != (h, w):\n",
    "        img = cv2.resize(img, (w, h), interpolation=cv2.INTER_AREA)\n",
    "    writer.write(img)\n",
    "\n",
    "writer.release()\n",
    "print(\"30fps 비디오 저장 완료:\", SAVE_MP4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
