{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "083c0213",
   "metadata": {},
   "source": [
    "# ê²½ë¡œ ì§€ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6e187b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™•ì¸í•  í–‰ ë²ˆí˜¸\n",
    "TARGET_ROW = 1084"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e534d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì¡´ì¬: /workspace/nas203/ds_RehabilitationMedicineData/IDs/Kimjihoo/3_project_HCCmove/data/1_FRAME/sample_data/ICU_sample_video/ê²½ì‚¬ì§„ ì¹¨ëŒ€ì—ì„œ ëª¸í†µ ëŒë¦¬ê¸°\n",
      "âœ… ì¡´ì¬: /workspace/nas203/ds_RehabilitationMedicineData/IDs/Kimjihoo/3_project_HCCmove/data/2_KEYPOINTS/sample_data/ICU_sample_video/ê²½ì‚¬ì§„ ì¹¨ëŒ€ì—ì„œ ëª¸í†µ ëŒë¦¬ê¸°\n",
      "ğŸ“ ìƒì„± ì™„ë£Œ: /workspace/nas203/ds_RehabilitationMedicineData/IDs/Kimjihoo/3_project_HCCmove/data/4_INTERP_DATA/sample_data/ICU_sample_video/ê²½ì‚¬ì§„ ì¹¨ëŒ€ì—ì„œ ëª¸í†µ ëŒë¦¬ê¸°\n",
      "\n",
      "is_train = True\n",
      "ğŸ¯ í˜„ì¬ ì²˜ë¦¬ ëŒ€ìƒ: ê²½ì‚¬ì§„ ì¹¨ëŒ€ì—ì„œ ëª¸í†µ ëŒë¦¬ê¸°\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil  # íŒŒì¼ ë³µì‚¬ìš©\n",
    "import json\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "# -------------------------------------------------------\n",
    "BASE_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/Kimjihoo/3_project_HCCmove/data\")\n",
    "CSV_PATH = BASE_DIR / \"metadata_yolo_final.csv\"\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# CSV ë¡œë“œ ë° í–‰ ì ‘ê·¼\n",
    "# -------------------------------------------------------\n",
    "meta = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# ê°œë³„ ê²½ë¡œ ìƒì„±\n",
    "# -------------------------------------------------------\n",
    "FRAME_DIR = BASE_DIR / str(meta.loc[TARGET_ROW]['frame_path'])\n",
    "KEYPOINTS_DIR = BASE_DIR / str(meta.loc[TARGET_ROW]['keypoints_path'])\n",
    "INTERP_DIR = BASE_DIR / str(meta.loc[TARGET_ROW]['interp_json_path'])\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° í´ë” ìƒì„±\n",
    "# -------------------------------------------------------\n",
    "for p in [FRAME_DIR, KEYPOINTS_DIR, INTERP_DIR]:\n",
    "    if not p.exists():\n",
    "        if p == INTERP_DIR:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"ğŸ“ ìƒì„± ì™„ë£Œ: {p}\")\n",
    "        else:\n",
    "            print(f\"âŒ ì—†ìŒ: {p}\")\n",
    "    else:\n",
    "        print(f\"âœ… ì¡´ì¬: {p}\")\n",
    "\n",
    "print(f\"\\nis_train = {meta.loc[TARGET_ROW]['is_train']}\")\n",
    "print(f\"ğŸ¯ í˜„ì¬ ì²˜ë¦¬ ëŒ€ìƒ: {Path(FRAME_DIR).name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253db01d",
   "metadata": {},
   "source": [
    "# í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0b233",
   "metadata": {},
   "source": [
    "## Frame ì‹œê°í™” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3efc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def plot_skeleton_overlay(FRAME_INDEX: int):\n",
    "    \"\"\"\n",
    "    ì§€ì •í•œ í”„ë ˆì„ì˜ skeleton overlayë¥¼ í‘œì‹œ (ëª¨ë“  keypoints í‘œì‹œ, ì–¼êµ´ ì œì™¸)\n",
    "\n",
    "    Args:\n",
    "        FRAME_INDEX (int): í™•ì¸í•  í”„ë ˆì„ ë²ˆí˜¸ (ì˜ˆ: 248)\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # ìƒ‰ìƒ ë° keypoint ê·¸ë£¹ ì •ì˜\n",
    "    # -------------------------------------------------------\n",
    "    COLOR_SK = (50, 50, 50)     # Skeleton = ì§™ì€ íšŒìƒ‰\n",
    "    COLOR_L  = (0, 0, 255)      # ì™¼ìª½ keypoints = íŒŒë‘ (Matplotlibì€ RGB ìˆœì„œë¼ ë°˜ëŒ€ë¡œ)\n",
    "    COLOR_R  = (255, 0, 0)      # ì˜¤ë¥¸ìª½ keypoints = ë¹¨ê°•\n",
    "    COLOR_NEUTRAL = (0, 255, 0) # ì¤‘ì•™ë¶€ keypoints = ì´ˆë¡\n",
    "\n",
    "    LEFT_POINTS  = [5,7,9,11,13,15]   # ì™¼ìª½ ê´€ì ˆ ì¸ë±ìŠ¤\n",
    "    RIGHT_POINTS = [6,8,10,12,14,16]  # ì˜¤ë¥¸ìª½ ê´€ì ˆ ì¸ë±ìŠ¤\n",
    "    EXCLUDE_POINTS = [0,1,2,3,4]      # ì œì™¸í•  keypoints (ì–¼êµ´ ë¶€ìœ„)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # JSON ë¡œë“œ\n",
    "    # -------------------------------------------------------\n",
    "    json_path = KEYPOINTS_DIR / f\"{FRAME_INDEX:06d}.json\"\n",
    "    if not json_path.exists():\n",
    "        raise FileNotFoundError(f\"âŒ JSON íŒŒì¼ ì—†ìŒ: {json_path}\")\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    keypoints = np.array(data[\"instance_info\"][0][\"keypoints\"])  # (17, 2)\n",
    "    skeleton = np.array(data[\"meta_info\"][\"skeleton_links\"])     # ì—°ê²°ìŒ\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # í”„ë ˆì„ ë¡œë“œ\n",
    "    # -------------------------------------------------------\n",
    "    frame_path = FRAME_DIR / f\"{FRAME_INDEX:06d}.jpg\"\n",
    "    if not frame_path.exists():\n",
    "        raise FileNotFoundError(f\"âŒ í”„ë ˆì„ ì—†ìŒ: {frame_path}\")\n",
    "    frame = cv2.imread(str(frame_path))\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # PLOT\n",
    "    # -------------------------------------------------------\n",
    "    plt.figure(figsize=(8, 12))\n",
    "    plt.imshow(frame)\n",
    "\n",
    "    # Skeleton í‘œì‹œ\n",
    "    for (i1, i2) in skeleton:\n",
    "        if i1 in EXCLUDE_POINTS or i2 in EXCLUDE_POINTS:\n",
    "            continue\n",
    "        x1, y1 = keypoints[i1]\n",
    "        x2, y2 = keypoints[i2]\n",
    "        plt.plot([x1, x2], [y1, y2], color=np.array(COLOR_SK)/255.0, linewidth=2, alpha=0.8)\n",
    "\n",
    "    # Keypoints í‘œì‹œ\n",
    "    for i, (x, y) in enumerate(keypoints):\n",
    "        if i in EXCLUDE_POINTS:\n",
    "            continue\n",
    "        if i in LEFT_POINTS:\n",
    "            color = np.array(COLOR_L)/255.0\n",
    "        elif i in RIGHT_POINTS:\n",
    "            color = np.array(COLOR_R)/255.0\n",
    "        else:\n",
    "            color = np.array(COLOR_NEUTRAL)/255.0\n",
    "        plt.scatter(x, y, color=color, s=40, edgecolors='black', linewidths=0.5)\n",
    "        plt.text(x + 5, y - 5, str(i), fontsize=8, color='black')\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Frame {FRAME_INDEX:06d} Skeleton Overlay\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3d01a6",
   "metadata": {},
   "source": [
    "## ì„ í˜• ë³´ê°„ í•¨ìˆ˜\n",
    "ë‹¨ì¼ ë³´ê°„ ì›í• ì‹œ  \n",
    "ex. Frame 5 -> range(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9cb4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_json_keypoints(target_kp: int, interp_range: range):\n",
    "    global KEYPOINTS_DIR  # ìƒìœ„ ìŠ¤ì½”í”„ì—ì„œ ì œì–´ë˜ëŠ” ì „ì—­ ë³€ìˆ˜ ì‚¬ìš©\n",
    "    print(f\"[INFO] ë³´ê°„ ëŒ€ìƒ keypoint: {target_kp}, frame range: {interp_range.start}-{interp_range.stop - 1}\")\n",
    "    print(f\"[INFO] ëŒ€ìƒ í´ë”: {KEYPOINTS_DIR}\")\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # ëª¨ë“  JSON íŒŒì¼ ë¡œë“œ ë° keypoint ì¢Œí‘œ ì¶”ì¶œ\n",
    "    # -------------------------------------------------------\n",
    "    json_files = sorted(KEYPOINTS_DIR.glob(\"*.json\"))                     # í´ë” ë‚´ JSON íŒŒì¼ ë¦¬ìŠ¤íŠ¸\n",
    "    all_kps = []                                                          # ëª¨ë“  keypoints ì €ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "    for jf in json_files:                                                 # ê° JSON íŒŒì¼ ìˆœíšŒ\n",
    "        with open(jf, \"r\") as f:                                          # JSON ì—´ê¸°\n",
    "            data = json.load(f)                                           # JSON íŒŒì‹±\n",
    "        kp = data[\"instance_info\"][0][\"keypoints\"]                        # ì²« ë²ˆì§¸ ì¸ìŠ¤í„´ìŠ¤ì˜ keypoints\n",
    "        all_kps.append(kp)                                                # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€\n",
    "\n",
    "    all_kps = np.array(all_kps)                                           # numpy ë°°ì—´ë¡œ ë³€í™˜ (shape: [frame, 17, 2])\n",
    "    print(f\"[INFO] keypoints shape: {all_kps.shape}\")\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # ë³´ê°„ ëŒ€ìƒ í”„ë ˆì„ ì œì™¸í•œ ì„ í˜• ë³´ê°„ ìˆ˜í–‰\n",
    "    # -------------------------------------------------------\n",
    "    frames = np.arange(len(all_kps))                                      # ì „ì²´ í”„ë ˆì„ ì¸ë±ìŠ¤\n",
    "    x_vals = all_kps[:, target_kp, 0]                                     # X ì¢Œí‘œ\n",
    "    y_vals = all_kps[:, target_kp, 1]                                     # Y ì¢Œí‘œ\n",
    "\n",
    "    valid_mask = np.ones_like(frames, dtype=bool)                         # ì „ì²´ True ë§ˆìŠ¤í¬ ìƒì„±\n",
    "    valid_mask[interp_range.start:interp_range.stop] = False              # ë³´ê°„ ëŒ€ìƒ êµ¬ê°„ë§Œ False ì²˜ë¦¬\n",
    "\n",
    "    interp_x = np.interp(frames, frames[valid_mask], x_vals[valid_mask])  # Xì¢Œí‘œ ì„ í˜• ë³´ê°„\n",
    "    interp_y = np.interp(frames, frames[valid_mask], y_vals[valid_mask])  # Yì¢Œí‘œ ì„ í˜• ë³´ê°„\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # ë³´ê°„ ê²°ê³¼ë¥¼ ê¸°ì¡´ JSONì— ë®ì–´ì“°ê¸°\n",
    "    # -------------------------------------------------------\n",
    "    for i, jf in enumerate(json_files):                                   # ê° í”„ë ˆì„ ìˆœíšŒ\n",
    "        if interp_range.start <= i <= interp_range.stop - 1:              # ë³´ê°„ ëŒ€ìƒ í”„ë ˆì„ë§Œ ìˆ˜ì •\n",
    "            with open(jf, \"r\") as f:                                      # JSON ì½ê¸°\n",
    "                data = json.load(f)                                       # JSON íŒŒì‹±\n",
    "\n",
    "            # keypoint ì¢Œí‘œë¥¼ ë³´ê°„ê°’ìœ¼ë¡œ êµì²´\n",
    "            data[\"instance_info\"][0][\"keypoints\"][target_kp][0] = float(interp_x[i])  # X ë³´ê°„ê°’\n",
    "            data[\"instance_info\"][0][\"keypoints\"][target_kp][1] = float(interp_y[i])  # Y ë³´ê°„ê°’\n",
    "\n",
    "            # ë®ì–´ì“°ê¸° ì €ì¥ (ì›ë³¸ JSON ì—…ë°ì´íŠ¸)\n",
    "            with open(jf, \"w\") as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\nâœ… Frame {interp_range.start}~{interp_range.stop - 1} êµ¬ê°„ ë³´ê°„ ì™„ë£Œ ë° JSON ë®ì–´ì“°ê¸° ì™„ë£Œ.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dedb28d",
   "metadata": {},
   "source": [
    "## Keypoints ê³ ì • í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cba136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_keypoint(KEYPOINTS_DIR: Path, OUTPUT_PATH: Path, target_kps, ref_frame: int):\n",
    "    \"\"\"\n",
    "    ì—¬ëŸ¬ keypointë¥¼ ê¸°ì¤€ í”„ë ˆì„(ref_frame)ì˜ ì¢Œí‘œë¡œ ì „ì²´ í”„ë ˆì„ì— ê³ ì •.\n",
    "    ê²°ê³¼ëŠ” OUTPUT_PATHì— ë³„ë„ë¡œ ì €ì¥ (ì›ë³¸ JSONì€ ë³´ì¡´).\n",
    "\n",
    "    Args:\n",
    "        KEYPOINTS_DIR (Path): ì›ë³¸ keypoints JSON í´ë” ê²½ë¡œ\n",
    "        OUTPUT_PATH (Path): ìˆ˜ì •ëœ JSON ì €ì¥ ê²½ë¡œ (ë³´í†µ 4_INTERP_DATA)\n",
    "        target_kps (int | list[int]): ê³ ì •í•  keypoint ì¸ë±ìŠ¤(ë“¤)\n",
    "        ref_frame (int): ê¸°ì¤€ í”„ë ˆì„ ë²ˆí˜¸ (ì˜ˆ: 266)\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # ì…ë ¥ íƒ€ì… ë³´ì •\n",
    "    # -------------------------------------------------------\n",
    "    if isinstance(target_kps, int):\n",
    "        target_kps = [target_kps]\n",
    "\n",
    "    OUTPUT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # ê¸°ì¤€ í”„ë ˆì„ ë¡œë“œ\n",
    "    # -------------------------------------------------------\n",
    "    ref_path = KEYPOINTS_DIR / f\"{ref_frame:06d}.json\"\n",
    "    if not ref_path.exists():\n",
    "        raise FileNotFoundError(f\"âŒ ê¸°ì¤€ í”„ë ˆì„ {ref_frame:06d}.json ì—†ìŒ\")\n",
    "\n",
    "    with open(ref_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        ref_data = json.load(f)\n",
    "\n",
    "    ref_kps = np.array(ref_data[\"instance_info\"][0][\"keypoints\"])\n",
    "    freeze_coords = {kp: ref_kps[kp] for kp in target_kps}\n",
    "\n",
    "    print(f\"\\n[INFO] ê¸°ì¤€ í”„ë ˆì„ {ref_frame}ì˜ ê³ ì • ëŒ€ìƒ keypoints ì¢Œí‘œ:\")\n",
    "    for kp, coord in freeze_coords.items():\n",
    "        print(f\"  - KP {kp}: {coord}\")\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # ì „ì²´ í”„ë ˆì„ ë³µì‚¬ í›„ ìˆ˜ì •\n",
    "    # -------------------------------------------------------\n",
    "    json_files = sorted(KEYPOINTS_DIR.glob(\"*.json\"))\n",
    "    print(f\"[INFO] ì´ {len(json_files)}ê°œ í”„ë ˆì„ ì²˜ë¦¬ ì¤‘...\")\n",
    "\n",
    "    for json_path in tqdm(json_files, desc=f\"Freezing keypoints {target_kps}\"):\n",
    "        # ì›ë³¸ JSON ë¡œë“œ\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as fp:\n",
    "            data = json.load(fp)\n",
    "\n",
    "        kps = np.array(data[\"instance_info\"][0][\"keypoints\"])\n",
    "\n",
    "        # ì§€ì •ëœ keypoints ì¢Œí‘œ ê³ ì •\n",
    "        for kp, coord in freeze_coords.items():\n",
    "            kps[kp] = coord\n",
    "\n",
    "        data[\"instance_info\"][0][\"keypoints\"] = kps.tolist()\n",
    "\n",
    "        # ì¶œë ¥ ê²½ë¡œ (4_INTERP_DATA í•˜ìœ„ ë™ì¼ êµ¬ì¡°)\n",
    "        out_file = OUTPUT_PATH / json_path.name\n",
    "        with open(out_file, \"w\", encoding=\"utf-8\") as fp:\n",
    "            json.dump(data, fp, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"\\nâœ… keypoints {target_kps} ì „ì²´ í”„ë ˆì„ ê³ ì • ì™„ë£Œ (ê¸°ì¤€ frame {ref_frame})\")\n",
    "    print(f\"   â†’ ì¶œë ¥ ê²½ë¡œ: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0537592",
   "metadata": {},
   "source": [
    "## IQR ì‹œê°í™” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e525d44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8ec3c89",
   "metadata": {},
   "source": [
    "## Velocity ì‹œê°í™” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c075119e",
   "metadata": {},
   "source": [
    "## smoothing ì‹œê°í™” í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa4bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def smooth_keypoints(KEYPOINTS_DIR: Path, INTERP_DIR: Path, target_kps, sigma: float = 2.0):\n",
    "    \"\"\"\n",
    "    ì§€ì •í•œ ë‹¤ìˆ˜ì˜ keypoint(target_kps)ì˜ X,Y ì¢Œí‘œë¥¼ Gaussian smoothing í›„ \n",
    "    INTERP_DIR ê²½ë¡œì— JSON ë³µì‚¬ ë° ìˆ˜ì • ì €ì¥.\n",
    "\n",
    "    Args:\n",
    "        KEYPOINTS_DIR (Path): ì›ë³¸ keypoints JSON í´ë” ê²½ë¡œ\n",
    "        INTERP_DIR (Path): ë³´ê°„/ìŠ¤ë¬´ë”© JSON ì €ì¥ í´ë” ê²½ë¡œ\n",
    "        target_kps (int | list[int]): smoothing ëŒ€ìƒ keypoint ì¸ë±ìŠ¤ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸\n",
    "        sigma (float): Gaussian smoothing sigma ê°’ (ê¸°ë³¸=2.0)\n",
    "    \"\"\"\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # ì…ë ¥ê°’ ì •ë¦¬\n",
    "    # -------------------------------------------------------\n",
    "    if isinstance(target_kps, int):\n",
    "        target_kps = [target_kps]\n",
    "\n",
    "    json_files = sorted(KEYPOINTS_DIR.glob(\"*.json\"))\n",
    "    if not json_files:\n",
    "        raise FileNotFoundError(f\"âŒ JSON íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {KEYPOINTS_DIR}\")\n",
    "\n",
    "    INTERP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"[INFO] ì´ {len(json_files)}ê°œ í”„ë ˆì„, keypoints {target_kps} smoothing ì¤‘...\")\n",
    "    print(f\"[INFO] ì›ë³¸ í´ë”: {KEYPOINTS_DIR}\")\n",
    "    print(f\"[INFO] ì¶œë ¥ í´ë”: {INTERP_DIR}\")\n",
    "\n",
    "    # -------------------------------------------------------\n",
    "    # keypointë³„ smoothing\n",
    "    # -------------------------------------------------------\n",
    "    for kp in target_kps:\n",
    "        print(f\"\\n[INFO] â–¶ Keypoint {kp} smoothing ì‹œì‘ (Ïƒ={sigma})\")\n",
    "\n",
    "        # ì¢Œí‘œ ì¶”ì¶œ\n",
    "        x_values, y_values = [], []\n",
    "        for jfile in json_files:\n",
    "            with open(jfile, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            kps = np.array(data[\"instance_info\"][0][\"keypoints\"])\n",
    "            x_values.append(kps[kp, 0])\n",
    "            y_values.append(kps[kp, 1])\n",
    "\n",
    "        x_values = np.array(x_values)\n",
    "        y_values = np.array(y_values)\n",
    "\n",
    "        # Gaussian smoothing\n",
    "        x_smooth = gaussian_filter1d(x_values, sigma=sigma)\n",
    "        y_smooth = gaussian_filter1d(y_values, sigma=sigma)\n",
    "        print(f\"[INFO] Gaussian smoothing ì™„ë£Œ (Ïƒ={sigma}) â€” KP {kp}\")\n",
    "\n",
    "        # JSON ìˆ˜ì • ë° INTERP_DIRì— ì €ì¥\n",
    "        for i, jfile in enumerate(tqdm(json_files, desc=f\"Smoothing KP {kp}\")):\n",
    "            # ì›ë³¸ JSON ë³µì‚¬ í›„ ìˆ˜ì •\n",
    "            dest_path = INTERP_DIR / jfile.name\n",
    "            shutil.copy(jfile, dest_path)\n",
    "\n",
    "            with open(dest_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            kps = np.array(data[\"instance_info\"][0][\"keypoints\"])\n",
    "            kps[kp, 0] = x_smooth[i]\n",
    "            kps[kp, 1] = y_smooth[i]\n",
    "            data[\"instance_info\"][0][\"keypoints\"] = kps.tolist()\n",
    "\n",
    "            with open(dest_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"âœ… Keypoint {kp} smoothing ì™„ë£Œ (Ïƒ={sigma})\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501b90ff",
   "metadata": {},
   "source": [
    "## ì˜ìƒ ìƒì„± í•¨ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c1715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===========================================================\n",
    "# ë‹¨ì¼ Overlay ìƒì„± í•¨ìˆ˜\n",
    "# ===========================================================\n",
    "def create_overlay(frame_dir: str, json_dir: str, out_mp4: str, fps: int = 30,\n",
    "                   kp_radius: int = 4, line_thickness: int = 2):\n",
    "    \"\"\"\n",
    "    í”„ë ˆì„ + keypoints JSON â†’ overlay mp4 ìƒì„± (COCO 17kp êµ¬ì¡°)\n",
    "    - ì¢Œìš° ë°˜ì „ ì—†ìŒ\n",
    "    - 0~4ë²ˆ keypoints ì œì™¸ (ì–¼êµ´ ì œì™¸)\n",
    "    - L/R ìƒ‰ìƒ êµ¬ë¶„\n",
    "    - í•˜ë‹¨ ì•ˆë‚´ë¬¸êµ¬ í‘œì‹œ (\"L: Blue | R: Red\")\n",
    "    \"\"\"\n",
    "\n",
    "    frame_files = sorted(Path(frame_dir).glob(\"*.jpg\"))\n",
    "    if not frame_files:\n",
    "        print(f\"[WARN] No frames found in {frame_dir}\")\n",
    "        return\n",
    "\n",
    "    out_mp4 = Path(out_mp4)\n",
    "    out_mp4.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # í•´ìƒë„ í™•ì¸\n",
    "    sample = cv2.imread(str(frame_files[0]))\n",
    "    h, w = sample.shape[:2]\n",
    "    writer = cv2.VideoWriter(str(out_mp4), cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "\n",
    "    # ìƒ‰ìƒ ì„¤ì •\n",
    "    COLOR_SK = (50, 50, 50)   # Skeleton = ì§™ì€ íšŒìƒ‰\n",
    "    COLOR_L  = (255, 0, 0)    # ì™¼ìª½ keypoints = íŒŒë‘\n",
    "    COLOR_R  = (0, 0, 255)    # ì˜¤ë¥¸ìª½ keypoints = ë¹¨ê°•\n",
    "    COLOR_NEUTRAL = (0, 255, 0) # ì¤‘ì•™ë¶€ keypoints = ì´ˆë¡\n",
    "\n",
    "    LEFT_POINTS  = [5,7,9,11,13,15]\n",
    "    RIGHT_POINTS = [6,8,10,12,14,16]\n",
    "\n",
    "    for frame_path in tqdm(frame_files, total=len(frame_files), desc=f\"{Path(frame_dir).name}\", unit=\"frame\"):\n",
    "        frame = cv2.imread(str(frame_path))\n",
    "        json_path = Path(json_dir) / (frame_path.stem + \".json\")\n",
    "\n",
    "        if json_path.exists():\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            if \"instance_info\" in data and len(data[\"instance_info\"]) > 0:\n",
    "                inst = data[\"instance_info\"][0]\n",
    "                kpts = np.array(inst[\"keypoints\"])\n",
    "                skeleton = data.get(\"meta_info\", {}).get(\"skeleton_links\", [])\n",
    "\n",
    "                # Skeleton\n",
    "                for i, j in skeleton:\n",
    "                    if i < len(kpts) and j < len(kpts):\n",
    "                        if i < 5 or j < 5:\n",
    "                            continue\n",
    "                        pt1, pt2 = tuple(map(int, kpts[i])), tuple(map(int, kpts[j]))\n",
    "                        cv2.line(frame, pt1, pt2, COLOR_SK, line_thickness)\n",
    "\n",
    "                # Keypoints\n",
    "                for idx, (x, y) in enumerate(kpts):\n",
    "                    if idx < 5 or x <= 0 or y <= 0:\n",
    "                        continue\n",
    "                    if idx in LEFT_POINTS:\n",
    "                        color = COLOR_L\n",
    "                    elif idx in RIGHT_POINTS:\n",
    "                        color = COLOR_R\n",
    "                    else:\n",
    "                        color = COLOR_NEUTRAL\n",
    "                    cv2.circle(frame, (int(x), int(y)), kp_radius, color, -1)\n",
    "\n",
    "                # ì•ˆë‚´ ë¬¸êµ¬\n",
    "                legend_text = \"L: Blue   |   R: Red\"\n",
    "                cv2.putText(frame, legend_text, (20, h - 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        frame = cv2.flip(frame, 1)  # ì¢Œìš° ë°˜ì „ ë³µì›\n",
    "        writer.write(frame)\n",
    "\n",
    "    writer.release()\n",
    "    print(f\"âœ… Overlay ì™„ë£Œ â†’ {out_mp4}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sapiens)",
   "language": "python",
   "name": "sapiens"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
